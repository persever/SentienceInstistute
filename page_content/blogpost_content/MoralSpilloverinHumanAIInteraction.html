<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=fpjTOVmNbO4Lz34iLyptLUXza5VhXqVC6o75Eld_V98');ol.lst-kix_list_1-3{list-style-type:none}ol.lst-kix_list_1-4{list-style-type:none}.lst-kix_list_2-6>li:before{content:"\0025cf  "}.lst-kix_list_2-7>li:before{content:"\0025cb  "}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-4>li:before{content:"\0025cb  "}.lst-kix_list_2-5>li:before{content:"\0025a0  "}.lst-kix_list_2-8>li:before{content:"\0025a0  "}ol.lst-kix_list_1-1{list-style-type:none}ol.lst-kix_list_1-2{list-style-type:none}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}ol.lst-kix_list_1-7{list-style-type:none}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}ol.lst-kix_list_1-8{list-style-type:none}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ul.lst-kix_list_2-8{list-style-type:none}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}ul.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_1-0>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) ") "}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_2-0{list-style-type:none}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}.lst-kix_list_1-1>li:before{content:"" counter(lst-ctn-kix_list_1-1,lower-latin) ". "}.lst-kix_list_1-2>li:before{content:"" counter(lst-ctn-kix_list_1-2,lower-roman) ". "}ul.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_2-4{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_1-3>li:before{content:"" counter(lst-ctn-kix_list_1-3,decimal) ". "}.lst-kix_list_1-4>li:before{content:"" counter(lst-ctn-kix_list_1-4,lower-latin) ". "}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_1-7>li:before{content:"" counter(lst-ctn-kix_list_1-7,lower-latin) ". "}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}.lst-kix_list_1-5>li:before{content:"" counter(lst-ctn-kix_list_1-5,lower-roman) ". "}.lst-kix_list_1-6>li:before{content:"" counter(lst-ctn-kix_list_1-6,decimal) ". "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_list_2-0>li:before{content:"\0025cf  "}.lst-kix_list_2-1>li:before{content:"\0025cb  "}.lst-kix_list_1-8>li:before{content:"" counter(lst-ctn-kix_list_1-8,lower-roman) ". "}.lst-kix_list_2-2>li:before{content:"\0025a0  "}.lst-kix_list_2-3>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c53{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:154.9pt;border-top-color:#000000;border-bottom-style:solid}.c31{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#7f7f7f;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:77.5pt;border-top-color:#000000;border-bottom-style:solid}.c3{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#7f7f7f;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:77.4pt;border-top-color:#000000;border-bottom-style:solid}.c46{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:77.5pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:150.8pt;border-top-color:#000000;border-bottom-style:solid}.c29{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:104.2pt;border-top-color:#000000;border-bottom-style:solid}.c5{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:200.2pt;border-top-color:#000000;border-bottom-style:solid}.c22{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:146.2pt;border-top-color:#000000;border-bottom-style:solid}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:150.4pt;border-top-color:#000000;border-bottom-style:solid}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:12pt}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify;height:12pt}.c10{padding-top:20pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c48{padding-top:20pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;text-align:justify}.c30{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:12pt}.c37{padding-top:18pt;padding-bottom:4pt;line-height:1.0;page-break-after:avoid;text-align:justify}.c49{padding-top:18pt;padding-bottom:4pt;line-height:1.0;page-break-after:avoid;text-align:left}.c52{padding-top:20pt;padding-bottom:6pt;line-height:1.1500000000000001;page-break-after:avoid;text-align:justify}.c51{padding-top:20pt;padding-bottom:6pt;line-height:1.1500000000000001;page-break-after:avoid;text-align:left}.c7{color:#000000;text-decoration:none;vertical-align:baseline;font-size:12pt;font-style:normal}.c1{-webkit-text-decoration-skip:none;color:#0563c1;text-decoration:underline;text-decoration-skip-ink:none}.c24{text-decoration:none;vertical-align:baseline;font-size:20pt;font-style:normal}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c38{border-spacing:0;border-collapse:collapse;margin-right:auto}.c23{padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:justify}.c25{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c54{margin-left:-5.4pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c43{text-decoration:none;vertical-align:baseline;font-size:12pt}.c26{text-decoration:none;vertical-align:baseline;font-style:normal}.c39{vertical-align:baseline;font-size:12pt;font-style:normal}.c44{background-color:#ffffff;max-width:451.3pt;padding:72pt 72pt 72pt 72pt}.c17{font-weight:700;font-family:"Arial"}.c40{width:33%;height:1px}.c32{padding:0;margin:0}.c14{orphans:2;widows:2}.c11{font-size:11pt;color:#000000}.c0{font-weight:400;font-family:"Arial"}.c19{margin-left:36pt;padding-left:0pt}.c2{color:inherit;text-decoration:inherit}.c33{font-weight:400;font-family:"Calibri"}.c36{font-weight:700;font-family:"Calibri"}.c50{margin-left:18pt}.c34{height:0pt}.c27{font-size:10pt}.c18{color:#000000}.c41{height:12pt}.c15{font-size:11pt}.c47{font-size:15pt}.c45{background-color:#f5f5f5}.c28{color:#1155cc}.c35{vertical-align:super}.c20{margin-left:36pt}.c42{font-size:18pt}.c6{font-style:italic}.c8{height:22pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:12pt;font-family:"Calibri"}p{margin:0;color:#000000;font-size:12pt;font-family:"Calibri"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c44 doc-content"><div><p class="c12"><span class="c7 c33"></span></p></div><p class="c13 c14"><span class="c43 c0 c18 c6">Authors: Katerina Manoli, Janet Pauketat</span></p><p class="c12"><span class="c43 c0 c18 c6"></span></p><p class="c13 c14"><span class="c0 c6">Edited by Jacy Reese Anthis. </span><span class="c0 c18 c6 c43">Many thanks to Michael Dello-Iacovo, Merel Keijsers, Ali Ladak, and Brad Saad for their thoughtful feedback.</span></p><h1 class="c14 c51" id="h.jgmqlghwo066"><span class="c24 c0 c18">Summary</span></h1><p class="c13 c14"><span class="c0 c6">Moral spillover</span><span class="c0">&nbsp;is the transfer of moral attitudes or behaviors from one setting to another</span><span class="c0 c28">&nbsp;</span><span class="c0">(e.g., from one being to another, from one behavior to a related behavior, from one group today to related groups in the future). Examples include the </span><span class="c0">transfer of</span><span>&nbsp;</span><span class="c0">anti-slavery activism to animal rights activism (</span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sentienceinstitute.org/british-antislavery&amp;sa=D&amp;source=editors&amp;ust=1684390025502488&amp;usg=AOvVaw3GLC8cBCxScRvZRND2kFFM">Anthis and Anthis 2017</a></span><span class="c0">)</span><span class="c0">,</span><sup class="c0 c35"><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span class="c0">&nbsp;children&rsquo;s </span><span class="c0">moral consideration of a biological dog to a robot dog (</span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2016-48422-007&amp;sa=D&amp;source=editors&amp;ust=1684390025503061&amp;usg=AOvVaw1jWgLsUlDzyZoR_VRYYp9G">Chernyak and Gary 2016</a></span><span class="c0">)</span><span class="c0">, and household </span><span class="c0">energy conservation to water conservation (</span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0921344921001774&amp;sa=D&amp;source=editors&amp;ust=1684390025503428&amp;usg=AOvVaw3Elnu_FqUh9JmziJdhYzYK">Liu et al. 2021</a></span><span class="c0">)</span><span class="c0">. Moral spillover seems to be an important driver of </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0016328721000641&amp;sa=D&amp;source=editors&amp;ust=1684390025503756&amp;usg=AOvVaw3zKpk5NgUfjehwRauIaCBq">moral circle expansion</a></span><span class="c0">. Here, we review moral spillover research with a focus on human-AI interaction.</span><span>&nbsp;</span><span class="c0">P</span><span class="c0">sychological factors, such as pre-existing attitudes towards AIs, as well as AI attributes, such as human-likeness and social group membership, could influence moral spillover between humans and AIs. Spillover of moral consideration to AIs might be hindered by factors such as the </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/spc3.12265&amp;sa=D&amp;source=editors&amp;ust=1684390025504253&amp;usg=AOvVaw3ZXg6iMeTci-PkrngYlbkL">intention-action gap</a></span><span class="c0">&nbsp;and might be facilitated by interventions such as human-AI contact and promoting a core belief that the moral consideration of AIs is important. We conclude with future research suggestions to examine how pre-existing attitudes affect moral spillover, the potential backfiring of spillover interventions, how spillover affects AIs on a spectrum of similarity to humans, and how temporal spillover functions to shape moral consideration of future AIs, especially based on core beliefs about AI. </span></p><h1 class="c14 c52" id="h.6aevp7z97h5u"><span class="c24 c0 c18">Table of contents</span></h1><p class="c23"><span class="c25 c0"><a class="c2" href="#h.jgmqlghwo066">Summary</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.6aevp7z97h5u">Table of contents</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.z0ay041xj2ze">Introduction</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.8ub9rsi830s">Types of spillover</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.9ifkekxvmwxm">What factors shape the likelihood of moral spillover?</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.lmixdc2v5jt">What are the implications of human-AI interaction research for moral spillover?</a></span></p><p class="c23 c50"><span class="c25 c0"><a class="c2" href="#h.c7f2trae5117">&ldquo;Computers are social actors&rdquo;</a></span></p><p class="c23 c50"><span class="c25 c0"><a class="c2" href="#h.uwtlrinq1eh6">Social group membership</a></span></p><p class="c23 c50"><span class="c25 c0"><a class="c2" href="#h.uq2qw6mlkpih">Human and AI features</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.bdv2dry64m6k">What is the difference between the spillover of actions and intentions?</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.qc42eymkb64l">What interventions can we use to induce the spillover of moral consideration?</a></span></p><p class="c23"><span class="c25 c0"><a class="c2" href="#h.jxrvu05vmabb">What future research is needed?</a></span></p><h1 class="c10" id="h.z0ay041xj2ze"><span class="c0 c18 c24">Introduction</span></h1><p class="c13 c14"><span class="c0">The well-being of future </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience&amp;sa=D&amp;source=editors&amp;ust=1684390025506977&amp;usg=AOvVaw2smzJBJLflZVZj2j0zV4Mw">sentient artificial intelligences</a></span><sup class="c0"><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span class="c0">&nbsp;(AIs) depends in part on whether moral consideration transfers to them from consideration already extended to other beings, such as humans, nonhuman animals, and AIs who already exist.</span><sup class="c0"><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span class="c0">&nbsp;The</span><span class="c0">&nbsp;transfer of moral attitudes and behaviors, such as moral consideration, from one setting to another can be defined as </span><span class="c0 c6">moral spillover</span><span class="c0">.</span><sup class="c0"><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup><span class="c0">&nbsp;Moral spillover may be an important part of </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0016328721000641&amp;sa=D&amp;source=editors&amp;ust=1684390025507845&amp;usg=AOvVaw1xD4mrkNRv4HxfAZMSVHmq">moral circle expansion</a></span><span class="c0">, both for the circles of individual humans and of human societies. For example, a 2017 Sentience Institute </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sentienceinstitute.org/british-antislavery&amp;sa=D&amp;source=editors&amp;ust=1684390025508151&amp;usg=AOvVaw1q9Opzj1qrnSrIc7jiaQsP">report</a></span><span class="c0">&nbsp;on the 1800s anti-slavery movement found that the consideration anti-slavery activists had for humans transferred to animals, making them some of the first animal rights activists. </span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Given the </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ai100.stanford.edu/2021-report/standing-questions-and-responses/sq2-what-are-most-important-advances-ai&amp;sa=D&amp;source=editors&amp;ust=1684390025508925&amp;usg=AOvVaw3qP4opAPS6REALSck8xWpo">rapid growth</a></span><span class="c0">&nbsp;of AI application and sophistication and an increasing likelihood that the number of future sentient beings will be </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.overcomingbias.com/p/a-galaxy-on-earthhtml&amp;sa=D&amp;source=editors&amp;ust=1684390025509238&amp;usg=AOvVaw1sno7Vswj0yDM3EBFOvWzg">vast</a></span><span class="c0">, here we analyze whether the spillover of moral consideration is feasible or likely between beings that are granted (at least some) consideration (e.g., humans, animals) and future AIs. In psychology and human-robot interaction (HRI) studies, AIs are often used to improve the moral treatment of humans, suggesting that moral consideration can transfer from AIs to humans. For example, positive emotions from being hugged by a robot </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/document/8172336/&amp;sa=D&amp;source=editors&amp;ust=1684390025509563&amp;usg=AOvVaw3daDQcIHAowmLGH4kSfENn">spilled over</a></span><span class="c0">&nbsp;to increase donations to human-focused charities. Some research suggests that the transfer of moral consideration from humans or nonhuman animals to AIs is also possible. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2016-48422-007&amp;sa=D&amp;source=editors&amp;ust=1684390025509861&amp;usg=AOvVaw3DxVCfcOa4QqE3V76o_3Vb">A 2016 study</a></span><span class="c0">&nbsp;showed that 5- and 7-year-old children with biological dogs at home treated </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://robots.ieee.org/robots/aibo2018/&amp;sa=D&amp;source=editors&amp;ust=1684390025510130&amp;usg=AOvVaw23kWlHndk8A0SqAAEM17Be">robot dogs</a></span><span class="c0">&nbsp;better than children without biological dogs. This suggests that moral spillover to AIs might occur </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S2352250X21001378&amp;sa=D&amp;source=editors&amp;ust=1684390025510429&amp;usg=AOvVaw3XGjzc9DkF0n_efCz63C1Z">incidentally or automatically</a></span><span class="c0">&nbsp;as part of humans&rsquo; </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00822/full&amp;sa=D&amp;source=editors&amp;ust=1684390025510741&amp;usg=AOvVaw1PyMoDrXAWJA-InBKipY5G">social relationships</a></span><span class="c0">. </span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">We do not know whether or not moral consideration will reliably transfer to and across the diverse range of AIs with different appearances, inner features, or mental capacities who are </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://longtermrisk.org/risks-of-astronomical-future-suffering/&amp;sa=D&amp;source=editors&amp;ust=1684390025511261&amp;usg=AOvVaw2-Kzf4KFZVswtmVYwxNg0N">likely to proliferate</a></span><span class="c0">&nbsp;in the future. There is little evidence on whether or not moral consideration would transfer from very different beings to AIs who display very few or none of the same features. For instance, moral consideration of a biological dog might spill over to moral consideration of a robot dog but it may not spill over to moral consideration of a disembodied large language model like </span><span class="c0 c25"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/OpenAI%23Generative_models&amp;sa=D&amp;source=editors&amp;ust=1684390025511591&amp;usg=AOvVaw260hAdZlXdwAEp9n8NjAZe">GPT-n</a></span><span class="c0">. This might be especially significant if arguably superficial features such as appearance, substrate, or purpose override the effects of </span><span class="c0 c1"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s43681-023-00260-1&amp;sa=D&amp;source=editors&amp;ust=1684390025511907&amp;usg=AOvVaw2XgAH1FOWR1eXJiv7war4u">features that grant moral standing</a></span><span class="c7 c0">&nbsp;(e.g., sentience). For example, a sentient disembodied algorithm or a sentient cell-like robot, who could theoretically benefit from the transfer of moral consideration based on their sentience, might not. </span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">This post reviews research on moral spillover in the context of AIs and examines factors that might influence its occurrence. We suggest that spillover might foster the moral consideration of AIs and call for more research to investigate spillover effects on a range of current and future AIs.</span></p><h1 class="c10" id="h.8ub9rsi830s"><span class="c24 c0 c18">Types of spillover</span></h1><p class="c13 c14"><span class="c0">In economics, </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Spillover_(economics)&amp;sa=D&amp;source=editors&amp;ust=1684390025512708&amp;usg=AOvVaw3Iv0u8eufGx3mS-G-Vg4x-">spillovers</a></span><span class="c0">, also known as externalities, are a natural part of structural theories in which a transaction affects non-participants, such as if an event in an economy affects another&mdash;usually more dependent&mdash;economy. In epidemiology, a </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Spillover_infection&amp;sa=D&amp;source=editors&amp;ust=1684390025513024&amp;usg=AOvVaw3JUwkHf0j7NxrtiK0-3mSF">spillover event</a></span><span class="c0">&nbsp;occurs when a pathogen transfers from its </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Natural_reservoir&amp;sa=D&amp;source=editors&amp;ust=1684390025513314&amp;usg=AOvVaw0iP1UsC4FVcPplS0MrrRAP">reservoir population</a></span><span class="c0">, such as animals, to a novel host, such as humans. In psychology, a </span><span class="c0 c18"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2017-08484-007&amp;sa=D&amp;source=editors&amp;ust=1684390025513589&amp;usg=AOvVaw293XuKXiFTWsNYkhf2CDXO">spillover</a></span><span class="c0">&nbsp;occurs when the adoption of</span><span>&nbsp;</span><span class="c0">an attitude or behavior transfers to other related attitudes or behaviors. Based on the latter definition, moral spillover occurs when moral attitudes or behaviors towards a being or group of beings transfer to another setting (e.g., to another being or group of beings). </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2017-08484-007&amp;sa=D&amp;source=editors&amp;ust=1684390025513944&amp;usg=AOvVaw2EeYfeOsYQ9PtW3rML2eil">Nilsson et al. (2017</a></span><span class="c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2017-08484-007&amp;sa=D&amp;source=editors&amp;ust=1684390025514174&amp;usg=AOvVaw0D5L_H8ZPxLtqlWIcrp2qJ">) </a></span><span class="c0">suggested</span><span class="c0">&nbsp;a distinction between three types of spillover:</span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0 c6">Figure 1</span><span class="c7 c0">: Types of Spillover</span></p><p class="c13 c14"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 218.67px;"><img alt="" src="images/moral-spillover-in-human-ai-interaction/image1.png" style="width: 601.70px; height: 218.67px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ol class="c32 lst-kix_list_1-0 start" start="1"><li class="c13 c14 c19 li-bullet-0"><span class="c17 c18">Behavioral</span><span class="c0 c18">: Behavior A increases the probability of behavior B. </span><span>&nbsp; &nbsp; &nbsp;</span></li></ol><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14 c20"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0095069620300486&amp;sa=D&amp;source=editors&amp;ust=1684390025515255&amp;usg=AOvVaw1GsJaowe03O5F3NdzWuM2W">Carlsson and colleagues (2021)</a></span><span class="c0">&nbsp;showed that pro-environmental behaviors, such </span><span class="c0 c18">as conserving </span><span class="c0">water</span><span class="c0 c18">, can spill over to other pro-environmental behaviors, such as conserving </span><span class="c0">electricity</span><span class="c0 c18">. </span><span class="c0">In the context of AI, researchers could ask questions like, can a prosocial</span><sup class="c0 c35"><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span class="c7 c0">&nbsp;behavior towards AIs lead to other prosocial behaviors towards AIs? For example, could greeting an AI assistant spill over to protecting this assistant from mistreatment?</span></p><p class="c12"><span class="c7 c0"></span></p><ol class="c32 lst-kix_list_1-0" start="2"><li class="c13 c14 c19 li-bullet-0"><span class="c17 c18">Contextual</span><span class="c0 c18">: A behavior or attitude in context A increases the probability of this behavior or attitude in context B.</span></li></ol><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14 c20"><span class="c0 c18">Research on contextual AI moral spillover could address questions like, can the moral consideration of sentient beings such as </span><span class="c0">animals</span><span class="c0 c18">&nbsp;spill over to AIs (e.g., </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2016-48422-007&amp;sa=D&amp;source=editors&amp;ust=1684390025516339&amp;usg=AOvVaw3MUdRS6s0Pqr9N8OBCLun_">Chernyak and Gary 2016</a></span><span class="c7 c0">)? </span></p><p class="c12"><span class="c26 c11 c0"></span></p><ol class="c32 lst-kix_list_1-0" start="3"><li class="c13 c14 c19 li-bullet-0"><span class="c17 c18">Temporal</span><span class="c0 c18">: A behavior or attitude at </span><span class="c0">time point</span><span class="c0 c18">&nbsp;A increases the frequency of the same or similar behavior or attitude at (a temporally distant) </span><span class="c0">time point</span><span class="c0 c18">&nbsp;B.</span><sup class="c0 c18 c35"><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span class="c7 c0">&nbsp;</span></li></ol><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14 c20"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02699/full&amp;sa=D&amp;source=editors&amp;ust=1684390025517265&amp;usg=AOvVaw3o_OZNYSXGDsW780_yUkP_">Elf et al. (2019)</a></span><span class="c7 c0">&nbsp;showed that the frequency of pro-environmental behaviors, such as buying eco-friendly products, increased a year after their initial adoption. Temporal spillover may be especially important for AIs given that they are likely to proliferate in the future. Increasing the moral consideration of AIs now might increase the moral and social inclusion of sentient AIs hundreds of years in the future.</span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">Behavioral, contextual, and temporal spillovers can occur at the same time. These kinds of spillovers can also occur at multiple levels (e.g., from individual to individual, from individual to group, from group to group). Below are some examples.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c16 c14"><span class="c0 c6">Table 1:</span><span class="c7 c0">&nbsp;Examples of Spillover Types at Different Levels</span></p><p class="c4"><span class="c7 c0"></span></p><a id="t.4d3699aa403dd55bd8dbd5d2d2461ab22847bee5"></a><a id="t.0"></a><table class="c38"><tr class="c34"><td class="c29" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Type</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Level</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Example</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Behavioral</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Turning off an unused electronic device increases the probability of riding a bike to work</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Caring for a sick animal increases the probability of becoming vegan</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Volunteering at a refugee center increases the probability of advocating for human rights</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Contextual</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Saving water at home increases the probability of saving water at work</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Positive attitudes toward a biological dog increase the probability of positive attitudes toward robot dogs</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Donating to animal charities increases the probability of donating to AI charities</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Temporal</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">A donation to a charity increases the frequency of donations to this charity in the future </span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Purchasing an energy-saving lamp increases the frequency of purchasing energy-saving lamps in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Giving blood to patients in need increases the frequency of giving blood again in the future</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Behavioral x Contextual</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Saving electricity at work increases the probability of limiting food waste at home</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Caring for a pet at home increases the probability of acting compassionately toward animals in the wild</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Giving blood to patients in need increases the probability of volunteering to help flood victims</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Behavioral x Temporal</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Using a recycled product increases the frequency of recycling in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Treating a wounded animal increases the frequency of using animal-free products in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Voting for animal rights increases the frequency of volunteering at an animal shelter in the future</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Contextual x Temporal</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Helping an AI household assistant increases the frequency of helping an AI workplace assistant in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Donating for the treatment of a sick dog increases the frequency of donating to an animal charity in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Trying vegan food increases the frequency of trying other animal-free products in the future</span></p></td></tr><tr class="c8"><td class="c29" colspan="1" rowspan="3"><p class="c13"><span class="c7 c0">Behavioral x Contextual x Temporal</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to individual</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Conserving electricity at home increases the frequency of cycling to work in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Individual to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Positive attitudes towards a biological pet increase the frequency of voting for wild animal rights in the future</span></p></td></tr><tr class="c8"><td class="c22" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Group to group</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c13"><span class="c7 c0">Voting for AI rights increases the frequency of being kind to AI assistants at work in the future</span></p></td></tr></table><p class="c4"><span class="c43 c0 c18 c6"></span></p><p class="c13 c14"><span class="c0">The examples outlined in Table 1 involve the transfer of positive or prosocial </span><span>&nbsp; &nbsp; &nbsp;</span><span class="c0">attitudes and behaviors. However, negative attitudes and behaviors can also spill over. This transfer can also be behavioral (e.g., ignoring an AI&rsquo;s plea for help leads to turning off an AI without their consent), contextual (e.g., being rude to a household AI increases the probability of being rude to a workplace AI), or temporal (e.g., intentionally damaging one AI now leads to frequently damaging AIs at a later point). For instance, </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S1071581916301768&amp;sa=D&amp;source=editors&amp;ust=1684390025542458&amp;usg=AOvVaw1gSYs0DLwQC5QxsOXx0xv0">previous research</a></span><span class="c7 c0">&nbsp;has shown that feeling threatened by a highly autonomous AI increases negative attitudes toward all AIs. See Figure 2 for a possible taxonomy of how these spillover types might intersect. </span></p><p class="c12"><span class="c7 c0"></span></p><p class="c14 c16"><span class="c0 c6">Figure 2: </span><span class="c7 c0">Possible Taxonomy of Spillover Types</span></p><p class="c16 c14"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 559.06px; height: 385.50px;"><img alt="A picture containing text

Description automatically generated" src="images/moral-spillover-in-human-ai-interaction/image2.png" style="width: 559.06px; height: 385.50px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">In the moral domain, the transfer of positive attitudes and behaviors can be associated with increased moral consideration between different groups and settings, like when the moral consideration of a biological dog increased the moral consideration of a robot dog. The transfer of negative attitudes and behaviors might lead to decreased moral consideration. </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0010027712000820&amp;sa=D&amp;source=editors&amp;ust=1684390025543553&amp;usg=AOvVaw1WeJFe3kk6Rf_9fXkwXlf1">Uhlmann et al. (2012)</a></span><span class="c0">&nbsp;showed that negative evaluations of a criminal spill over to their biological relatives, who are then more likely to be punished by law than non-biological relatives. The transfer of negative attitudes and behaviors can pose a significant risk to the well-being of sentient AIs, especially if they are</span><span>&nbsp;</span><span class="c0">held to different standards than other entities. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.degruyter.com/document/doi/10.1515/pjbr-2020-0017/html?lang%3Den&amp;sa=D&amp;source=editors&amp;ust=1684390025544108&amp;usg=AOvVaw1GKGcCWPKRKSonaCiUx9Cz">Bartneck and Keijsers (2020)</a></span><span class="c7 c0">&nbsp;showed that a mistreated robot who fights back is perceived as more abusive than a mistreated human who fights back. The transfer of negative attitudes towards one AI to all AIs could decrease the moral consideration of AIs and obstruct their inclusion in the moral circle.</span></p><h1 class="c10" id="h.9ifkekxvmwxm"><span class="c24 c0 c18">What factors shape the likelihood of moral spillover?</span></h1><p class="c13 c14"><span class="c7 c0">Whether or not spillover occurs depends on factors such as personality traits and social context. The impact of these factors on spillover has been studied largely in the context of environmental behavior. The same factors are likely valuable for understanding when and how moral spillover applies to AIs. Table 2 summarizes some factors identified in previous research.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c16 c14"><span class="c0 c6">Table 2</span><span class="c7 c0">: Factors Influencing the Occurrence of Spillover</span></p><p class="c4"><span class="c7 c0"></span></p><a id="t.db38eee223e85e74f635c56392f98cb3eb79c4b6"></a><a id="t.1"></a><table class="c38"><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Factor</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Example</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13"><span class="c7 c17">Source(s)</span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">Pre-existing attitudes</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Contact with a robot spilled over to more negative attitudes toward all robots for people who already had negative attitudes towards robots. &nbsp;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/7745228&amp;sa=D&amp;source=editors&amp;ust=1684390025547457&amp;usg=AOvVaw3LHG-PEQetquD_MssBl5MZ">Wullenkord et al., 2016</a></span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">P</span><span class="c0">ersonality traits</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Trusting an individual robot spilled over to trusting robots in general for people who were more extroverted and open to experience. </span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s12369-016-0357-8&amp;sa=D&amp;source=editors&amp;ust=1684390025549788&amp;usg=AOvVaw0ckzPhxcUN55wf9JeQP-MS">Ivaldi et al., 2017</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fpsyg.2020.568256/full&amp;sa=D&amp;source=editors&amp;ust=1684390025550443&amp;usg=AOvVaw1o0ONGz40lfWz0_jPivZwB">Oksanen et al., 2020</a></span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">Self-identity</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">A pro-environmental behavior spilled over to other pro-environmental behaviors more so for people who identified with caring about the environment. </span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.tandfonline.com/doi/abs/10.1080/13504622.2016.1250148?journalCode%3Dceer20&amp;sa=D&amp;source=editors&amp;ust=1684390025551790&amp;usg=AOvVaw2rtdOIdHSXKmPX_y0o5mVu">Nilsson, Bergquist &amp; Schulz, 2017</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://journals.sagepub.com/doi/abs/10.1177/0013916512475209&amp;sa=D&amp;source=editors&amp;ust=1684390025552311&amp;usg=AOvVaw0DXV6r0caH78raK9JI5cTg">Van der Werff, Steg &amp; Keizer, 2014</a></span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">Social learning</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Interacting with a robot that acted prosocially towards humans spilled over to increased prosocial treatment of other humans.</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563221000340&amp;sa=D&amp;source=editors&amp;ust=1684390025553575&amp;usg=AOvVaw3XDzV5Lvoq615rOTIbEdC0">Peter, </a></span><span class="c25 c0 c45"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563221000340&amp;sa=D&amp;source=editors&amp;ust=1684390025553877&amp;usg=AOvVaw0EzEfZq2Z8xEHSOLdXYXRd">K&uuml;hne</a></span><span class="c25 c0 c45 c47"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563221000340&amp;sa=D&amp;source=editors&amp;ust=1684390025554174&amp;usg=AOvVaw3iZWUwWDm9JwMvUsfMlJso">&nbsp;</a></span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563221000340&amp;sa=D&amp;source=editors&amp;ust=1684390025554487&amp;usg=AOvVaw2uLZbB6Wf0wfTY36JKvtiA">&amp; Barco, 2021</a></span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">Perceived value/impact</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Purchasing an ethical good spilled over to purchasing another ethical good more so for people who considered ethical purchases socially impactful.</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fpsyg.2021.668399/full&amp;sa=D&amp;source=editors&amp;ust=1684390025555821&amp;usg=AOvVaw1wgHBDIPYpJCfA47iLak7q">Schumann et al., 2021</a></span></p></td></tr><tr class="c34"><td class="c9" colspan="1" rowspan="1"><p class="c16 c14"><span class="c0">Similarity</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">A pro-environmental behavior spilled over to other pro-environmental behaviors more when these behaviors were similar (e.g., turning off a light and turning of a computer when leaving a room).</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0272494414000516&amp;sa=D&amp;source=editors&amp;ust=1684390025557095&amp;usg=AOvVaw1g0R2zI-of-0hxCBhN9ZEE">Littleford, Ryley &amp; Firth, 2014</a></span><span class="c0 c7">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.tandfonline.com/doi/abs/10.1080/13504622.2016.1250148?journalCode%3Dceer20&amp;sa=D&amp;source=editors&amp;ust=1684390025557582&amp;usg=AOvVaw23C3UNl4Ndjagq7CQLCch3">Nilsson, Bergquist &amp; Schulz, 2017</a></span></p></td></tr></table><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">One of the more studied factors shaping whether or not spillover occurs is pre-existing attitudes. If pre-existing attitudes towards a spillover target are negative, then the transfer of negative attitudes and behaviors is more likely. If pre-existing attitudes are positive, then the transfer of positive attitudes and behaviors is more likely. Below are three notable studies:</span></p><ul class="c32 lst-kix_list_2-0 start"><li class="c13 c14 c19 li-bullet-0"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0272494419306218?via%253Dihub&amp;sa=D&amp;source=editors&amp;ust=1684390025558320&amp;usg=AOvVaw3u_RDAfrcGENVlq88w-T9x">Henn et al. (2020)</a></span><span class="c25 c0">&nbsp;</span><span class="c7 c0">showed that pre-existing attitudes were the driving force behind spillovers in pro-environmental behavior across two separate cohorts: pre-existing positive attitudes towards the environment led to greater spillover between different kinds of pro-environmental behaviors (e.g., saving electricity and saving water). </span></li><li class="c13 c14 c19 li-bullet-0"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/7745228&amp;sa=D&amp;source=editors&amp;ust=1684390025558806&amp;usg=AOvVaw2EtruLglVwYPZaLuxvCQhN">Wullenkord et al. (2016)</a></span><span class="c7 c0">&nbsp;showed that pre-existing negative emotions towards robots spilled over to feeling more negative emotions for robots in general following contact with a robot, compared to a control condition that involved no contact.</span></li><li class="c13 c14 c19 li-bullet-0"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/5598679&amp;sa=D&amp;source=editors&amp;ust=1684390025559215&amp;usg=AOvVaw3HYgMydhCmmDoyiwE-ZW5A">Stafford et al. (2010)</a></span><span class="c7 c0">&nbsp;showed that pre-existing positive attitudes towards robots became more pronounced after meeting a robot; suggesting that the transfer of positive attitudes from one robot to all robots is easier when positive attitudes towards robots are already present.</span></li></ul><h1 class="c10" id="h.lmixdc2v5jt"><span class="c24 c0 c18">What are the implications of human-AI interaction research for moral spillover? </span></h1><p class="c13 c14"><span class="c7 c0">General themes in human-AI interaction have emerged from HRI research: &ldquo;computers are social actors,&rdquo; the importance of social group membership, and how human and AI features affect interactions. In this section, we consider what these themes imply for moral spillover between humans and AIs, focusing on their implications for the moral consideration of AIs.</span></p><h2 class="c37 c14" id="h.c7f2trae5117"><span class="c26 c0 c18 c42">&ldquo;Computers are social actors&rdquo;</span></h2><p class="c13 c14"><span class="c0">The </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://dl.acm.org/doi/10.1145/191666.191703&amp;sa=D&amp;source=editors&amp;ust=1684390025560103&amp;usg=AOvVaw3XEH-y89tgEhsIKuJ1r6co">&ldquo;computers are social actors&rdquo; (CASA) framework</a></span><span class="c0">&nbsp;suggests that machines with human-like capacities, such as verbal or written communication, interactivity (e.g., a response when a button is pressed), and the ability to perform traditional human tasks elicit an automatic attribution of social capacities. This affects responses to them. For example, </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.mdpi.com/2414-4088/3/1/20&amp;sa=D&amp;source=editors&amp;ust=1684390025560423&amp;usg=AOvVaw0rwmUzGDAjHphMx0x1KkFt">Lee et al. (2019)</a></span><span class="c7 c0">&nbsp;showed that people felt more positively towards autonomous vehicle voice agents who conformed to social role stereotypes (i.e., informative male voice and social female voice) compared to agents who did not.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">What does CASA imply for moral spillover? Moral spillover might be automatic between humans and AIs because of humans&rsquo; propensity to think of AIs as social actors.</span><span>&nbsp;</span><span class="c0">Moral spillover might occur more for AIs with human-like capacities, given that such</span><span>&nbsp;</span><span class="c0">features are blatant CASA cues. Some studies using the CASA framework have shown the transfer of consideration from AIs to humans. For example, </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563221000340&amp;sa=D&amp;source=editors&amp;ust=1684390025561066&amp;usg=AOvVaw3VaLUKjjy_wTyR35SPkrYJ">Peter et al. (2021)</a></span><span class="c0">&nbsp;showed that people who interacted with a prosocial robot, compared to a less prosocial robot, gave more resources to other humans.</span><span>&nbsp;</span><span class="c7 c0">Whether or not similar spillover effects emerge from humans towards AIs is an open question. For instance, the spillover of consideration from humans to AIs could be hindered for AIs who do not display enough human-like capacities (e.g., communication, emotional expression) to trigger CASA attributions.</span></p><h2 class="c14 c37" id="h.uwtlrinq1eh6"><span class="c26 c0 c18 c42">Social group membership</span></h2><p class="c13 c14"><span class="c0">Social group membership will likely impact moral spillover from humans to AIs since AIs are increasingly coexisting with humans in </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.techtarget.com/iotagenda/answer/What-is-human-robot-teaming-and-what-are-its-benefits&amp;sa=D&amp;source=editors&amp;ust=1684390025561742&amp;usg=AOvVaw3lMrRIG0O-LLBRuhMJxGlY">various group settings</a></span><span class="c0">. Generally, people tend to favor </span><span class="c0 c6">ingroups </span><span class="c0">(i.e., members of the same social group) over </span><span class="c0 c6">outgroups</span><span class="c0">, (i.e., members of another social group). </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2014-37732-001&amp;sa=D&amp;source=editors&amp;ust=1684390025562178&amp;usg=AOvVaw2e2kq4mZd_FPDqIFam0AgC">Ingroup favoritism</a></span><span class="c7 c0">&nbsp;increases cooperation with members of the same group, which can be based on features such as ethnicity, religion, gender, and ideology. </span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Moral consideration for ingroup humans could spill over onto ingroup AIs and consideration for ingroup AIs could spill on to other AIs. Shared social group membership can also translate into refusal to harm an ingroup AI. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/8172280&amp;sa=D&amp;source=editors&amp;ust=1684390025562675&amp;usg=AOvVaw2YmqKOu8JhF55Iua7N5fAR">Sembroski et al. (2017)</a></span><span class="c0">&nbsp;found that people refused to turn off a robot teammate despite being instructed to do so. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.5555/3523760.3523851&amp;sa=D&amp;source=editors&amp;ust=1684390025562978&amp;usg=AOvVaw2RZactBqe_wAsZFyFwIkQI">Preliminary research</a></span><span class="c0">&nbsp;has also shown that feelings of warmth towards a robot who was perceived as a friend spilled over to positive attitudes towards robots in general. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Ingroup-based spillover between humans and AIs likely has limits. </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S0747563220303320&amp;sa=D&amp;source=editors&amp;ust=1684390025563516&amp;usg=AOvVaw2xOpgoNAUPGkJSeuoIhwlL">Savela et al. (2021)</a></span><span class="c0">&nbsp;showed that humans identified less with a team that was mostly composed of robots, suggesting an underlying &ldquo;us&rdquo; versus &ldquo;them&rdquo; distinction that threatens the identity,</span><span>&nbsp;</span><span class="c7 c0">status, or control of the human minority. This could potentially inhibit the spillover of moral consideration between humans and AIs, at least in some cases. If humans and AIs coexist in social groups mostly composed of AIs (e.g., in the workplace), this could lead to the transfer of negative attitudes from the ingroup AIs to AIs in general, which might inhibit the inclusion of AIs in the moral circle. </span></p><h2 class="c14 c49" id="h.uq2qw6mlkpih"><span class="c0">Human and AI features</span></h2><p class="c13 c14"><span class="c7 c0">Additional research has focused on how the features of AIs (e.g., autonomy, usefulness/ease of operation) and of humans (e.g., cultural values towards AIs, owning AI or robotic devices) shape spillover. This research is likely important to understanding whether or not moral spillover occurs in the context of AIs. This research is summarized below. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c16 c14"><span class="c0 c6">Table 3</span><span class="c7 c0">: Human and AI Features Affecting Spillover</span></p><p class="c4"><span class="c7 c0"></span></p><a id="t.a65e1bb2069cc44956992e30a1c730cfd5406648"></a><a id="t.2"></a><table class="c54"><tr class="c41"><td class="c53" colspan="2" rowspan="1"><p class="c16 c14"><span class="c0">Agent Features</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c0">Example</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c0">Sources</span><span class="c7 c17">&nbsp;</span></p></td></tr><tr class="c34"><td class="c3" colspan="1" rowspan="2"><p class="c16 c14"><span class="c0">AI Features</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c16 c14"><span class="c7 c0">Autonomy</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Interacting with an AI with high perceived autonomy leads to a spillover of negative attitudes (e.g., higher perceived threat) towards AIs in general. </span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s12369-020-00672-7&amp;sa=D&amp;source=editors&amp;ust=1684390025567502&amp;usg=AOvVaw3vN-h84dxCZUz6IqQS9MwH">Zafari &amp; Koeszegi, 2020</a></span><span class="c0 c18">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S1071581916301768&amp;sa=D&amp;source=editors&amp;ust=1684390025568140&amp;usg=AOvVaw1WfgiP_ZKWaWrbpRpE5_Mm">Zlotowski, Yogeeswaran &amp; Bartneck, 2017</a></span></p></td></tr><tr class="c34"><td class="c31" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Use and Ease of Use</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Positive attitudes towards a service robot that is considered useful, enjoyable, and easy to operate spill over to robots in general. </span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.jbe-platform.com/content/journals/10.1075/is.12.3.04shi&amp;sa=D&amp;source=editors&amp;ust=1684390025570168&amp;usg=AOvVaw1mQns2hNO_MqgxPBmAcBQT">Shin &amp; Choo, 2011</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0378720618308437&amp;sa=D&amp;source=editors&amp;ust=1684390025570927&amp;usg=AOvVaw11tYKnLItjkKSzQDNaT3h2">Turje et al., 2020</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s12369-013-0220-0&amp;sa=D&amp;source=editors&amp;ust=1684390025571432&amp;usg=AOvVaw3MwxDrJwFqdRU1axkYWgJC">Smarr et al., 2014</a></span></p></td></tr><tr class="c34"><td class="c3" colspan="1" rowspan="2"><p class="c13 c14"><span class="c0">Human Features</span></p><p class="c12"><span class="c7 c17"></span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Cultural Attitudes Towards Technology </span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Culture might influence positive or negative perceptions of AIs based on a country&rsquo;s history, economy, and policies toward technology. For example, Chinese individuals tend to have more negative perceptions towards robots, whereas US individuals perceive robots as less threatening than humans. This could mean that the spillover of moral consideration towards AIs is dampened by cultural values in &nbsp;China but facilitated by cultural values in the US.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s00146-008-0181-2&amp;sa=D&amp;source=editors&amp;ust=1684390025573537&amp;usg=AOvVaw3oZGH2tcXJki00nk8jMP1F">MacDroman, Vasudevan &amp; Ho, 2009</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/5453165&amp;sa=D&amp;source=editors&amp;ust=1684390025574040&amp;usg=AOvVaw1czqVN9kCuEOBJn37kW88x">Wang et al., 2010</a></span></p></td></tr><tr class="c34"><td class="c31" colspan="1" rowspan="1"><p class="c13 c14"><span class="c7 c0">Experience/Technological Self-Efficacy</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c0 c18">Having a technology or engineering degree, prior exposure to robots, and higher self-efficacy with technology increases trust and moral consideration </span><span class="c0">of AIs</span><span class="c0 c18">.</span><span class="c0">&nbsp;This could facilitate moral spillover if moral consideration is transferred to AIs more readily for people with experience and self-efficacy with technology.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fpsyg.2020.568256/full&amp;sa=D&amp;source=editors&amp;ust=1684390025575746&amp;usg=AOvVaw0mPPYHygISny3T4jxm3Bkb">Oksanen et al., 2020</a></span><span class="c7 c0">;</span></p><p class="c13 c14"><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0747563222001947%23!&amp;sa=D&amp;source=editors&amp;ust=1684390025576306&amp;usg=AOvVaw2VVsFlBSv87UqbihITMIYV">Pauketat &amp; Anthis, 2022</a></span></p></td></tr></table><p class="c4"><span class="c7 c0"></span></p><h1 class="c10" id="h.bdv2dry64m6k"><span class="c24 c0 c18">What is the difference between the spillover of actions and intentions? </span></h1><p class="c13 c14"><span class="c0">The transfer of moral consideration could increase intentions to treat AIs morally, but this may not necessarily translate into action. For example</span><span>, </span><span class="c7 c0">even if someone recognizes the importance of including sentient AIs in the moral circle, they may not act on it by voting for a ban on AI discrimination. There is no guarantee that AIs will be treated well, even if moral consideration transfers to them from other beings. In the short term, humans might not intervene to help a mistreated AI. In the long term, human societies might not implement legislative infrastructure that safeguards the well-being of sentient AIs.</span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">This phenomenon is known as the </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/spc3.12265&amp;sa=D&amp;source=editors&amp;ust=1684390025577453&amp;usg=AOvVaw1f9VokX3L8FoiOcTHwePJ0">intention-action gap</a></span><span class="c0">&nbsp;and has been extensively studied in the context of environmental behavior. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.nature.com/articles/s41893-019-0263-9&amp;sa=D&amp;source=editors&amp;ust=1684390025577759&amp;usg=AOvVaw3qXzp-HrHUqd8NGwgu_duE">A recent meta-analysis</a></span><span class="c0">&nbsp;showed that a pro-environmental behavior spills over to the </span><span class="c0 c6">intention</span><span class="c0">&nbsp;to adopt similar behaviors but does not necessarily lead to action. For instance, taking shorter showers might spill over to an intention to start conserving electricity, but does not lead to turning off unused devices. In the context of human-AI interaction, most studies have focused on the spillover of intentions rather than behaviors. For example, </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/5598679&amp;sa=D&amp;source=editors&amp;ust=1684390025578151&amp;usg=AOvVaw2cEN7-FRHxko4juAlDS-SL">previous studies</a></span><span class="c0">&nbsp;have found that intentions to engage in prosocial interactions with all AIs increased after interacting with a single AI. However, positive attitudes do not necessarily</span><span class="c0">&nbsp;transfer to behavior or even </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0747563218304825&amp;sa=D&amp;source=editors&amp;ust=1684390025578496&amp;usg=AOvVaw2XBabmByN_xsj235dI413x">behavioral intentions</a></span><span class="c7 c0">. People might not seek out interactions with AIs even if they feel positively towards them or intend to engage in prosocial interactions.</span></p><p class="c12"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/spc3.12265&amp;sa=D&amp;source=editors&amp;ust=1684390025578973&amp;usg=AOvVaw0Z-ijy1KY5OJvr-L5--4q3">A synthesis of studies</a></span><span class="c0">&nbsp;suggested that the extent to which an action is in line with core beliefs (i.e., strong, long-held beliefs about oneself and the world) may underpin the intention-action gap. Intentions that align with core beliefs </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/abs/10.1002/1099-0992%2528200007/08%252930%253A4%253C533%253A%253AAID-EJSP6%253E3.0.CO%253B2-F&amp;sa=D&amp;source=editors&amp;ust=1684390025579319&amp;usg=AOvVaw15ZGwFdg1MBS_I2jpjAgkH">are more likely</a></span><span class="c0">&nbsp;to consistently translate into action compared to intentions that are motivated by other factors (e.g., the need to conform to group norms), which might lead to performative or temporary behaviors. In the environmental conservation literature, promoting core beliefs to protect the environment </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.nature.com/articles/s41893-019-0263-9&amp;sa=D&amp;source=editors&amp;ust=1684390025579652&amp;usg=AOvVaw39a2Xqnm366I1hXdg0fQvx">has been shown</a></span><span class="c7 c0">&nbsp;to increase the spillover between pro-environmental behaviors. Promoting core beliefs about the importance of the moral consideration of AIs is likely important to closing the intention-action gap so that AIs can benefit from the transfer of moral consideration. </span></p><h1 class="c10" id="h.qc42eymkb64l"><span class="c24 c0 c18">What interventions can we use to induce the spillover of moral consideration?</span></h1><p class="c13 c14"><span class="c0">A common technique used in HRI research is to examine attitude change towards robots in general after interaction with a single AI, usually a robot. This technique builds on a rich literature of human intergroup contact interventions that have been shown to effectively promote the spillover of moral consideration and reduction of prejudice between humans.</span><sup class="c0 c35"><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">HRI research has shown that human-AI contact might facilitate the transfer of moral consideration in the context of AIs. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/5598679&amp;sa=D&amp;source=editors&amp;ust=1684390025580592&amp;usg=AOvVaw25FSQGyGtqvo5nybGNqrgU">Stafford et al. (2010)</a></span><span class="c0">&nbsp;found that prosocial contact with a robot increased positive attitudes toward the robot and towards all robots. </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://dl.acm.org/doi/abs/10.5555/3523760.3523851&amp;sa=D&amp;source=editors&amp;ust=1684390025580918&amp;usg=AOvVaw1fMF3atnozl8Lz33gsS8sT">More recently</a></span><span class="c0">, researchers showed that mutual self-disclosure (e.g., sharing personal life details) with a robot increased positive perceptions of all robots. Additionally, contact with a robot caregiver </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S138650562030304X&amp;sa=D&amp;source=editors&amp;ust=1684390025581237&amp;usg=AOvVaw1ym5UGFuqLqQet4XLDpUHU">increased acceptance</a></span><span class="c0">&nbsp;of technology and AIs in general, and social interaction with a robot </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.liebertpub.com/doi/10.1089/cyber.2020.0162&amp;sa=D&amp;source=editors&amp;ust=1684390025581680&amp;usg=AOvVaw1Os90JZESMa_kN7tcX-sBb">has been shown</a></span><span class="c0">&nbsp;to increase positive perceptions of robots, regardless of their features. Positive attitudes after contact with a human-like robot </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/7451847&amp;sa=D&amp;source=editors&amp;ust=1684390025582155&amp;usg=AOvVaw0aTlPVYAZ5f95XbEm0WWxy">have been shown</a></span><span class="c0">&nbsp;to spill over to non-human-like robots. In-person interactions with a robot are not required to produce the spillover of positive attitudes and behaviors. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/6926300&amp;sa=D&amp;source=editors&amp;ust=1684390025582569&amp;usg=AOvVaw3KV7Kq4P3T499p1O0y8d2W">Wullenkord and Eyssel (2014)</a></span><span class="c0">&nbsp;</span><span class="c7 c0">demonstrated that imagining a prosocial interaction with a robot leads to positive attitudes and willingness to interact with other robots.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Another possible intervention to promote the transfer of moral consideration is </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/abs/pii/S0272494419306218?via%253Dihub&amp;sa=D&amp;source=editors&amp;ust=1684390025583127&amp;usg=AOvVaw0vGWkNdgNtTFVucGfoczFa">changing underlying negative attitudes</a></span><span class="c0">&nbsp;towards AIs. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s12369-016-0357-8&amp;sa=D&amp;source=editors&amp;ust=1684390025583435&amp;usg=AOvVaw2OPDXxsHzzhkG1TEhlnkI9">Some research</a></span><span class="c0">&nbsp;has shown that pre-existing negative attitudes towards AIs can persist even after a positive interaction with an AI, highlighting the significance of promoting positive attitudes towards AIs in order to facilitate the transfer of moral consideration. However, even if an intervention is successful in changing pre-existing attitudes towards AIs, the effective scope of this intervention might be limited to attitudes and intentions rather than behavior because of the intention-action gap.</span><span>&nbsp; &nbsp; &nbsp;</span><span class="c7 c0">&nbsp;</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">A </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://compass.onlinelibrary.wiley.com/journal/17519004&amp;sa=D&amp;source=editors&amp;ust=1684390025584012&amp;usg=AOvVaw2lk0Z4Sy6l1Ix6x3W-Zx5q">more effective intervention</a></span><span class="c0">&nbsp;might be to target core beliefs. As discussed previously, such beliefs are more likely to overcome the intention-action gap and translate into behavior. </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://psycnet.apa.org/record/2000-00512-004&amp;sa=D&amp;source=editors&amp;ust=1684390025584328&amp;usg=AOvVaw2zQMlMMNmJYERd0JKPUxVi">Sheeran and Orbell (2000)</a></span><span class="c7 c0">&nbsp;showed that individuals for whom exercising was part of their self-identity were better at translating intentions to exercise into action than &lsquo;non-exercisers&rsquo;. In the context of AIs, promoting the self-perception of being someone who cares about the well-being of all sentient beings might make it more likely for the transfer of moral consideration to produce positive behaviors towards sentient AIs. Likewise, holding a core belief that the moral consideration of AIs is important might improve the likelihood that moral consideration will transfer onto AIs.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Some interventions might be less effective in facilitating the transfer of moral consideration. Guilt interventions </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://www.nature.com/articles/s41893-019-0263-9&amp;sa=D&amp;source=editors&amp;ust=1684390025584866&amp;usg=AOvVaw0KeXmtzK0dw22bR9FCX7uZ">are ineffective</a></span><span class="c0">&nbsp;in producing spillover in the environmental domain, and may even backfire. Specifically, inducing guilt over failing to adopt a pro-environmental behavior decreased the likelihood of adopting other pro-environmental behaviors. Even though guilt increases initial intentions to perform a pro-environmental behavior, the </span><span class="c1 c0"><a class="c2" href="https://www.google.com/url?q=https://www.tandfonline.com/doi/abs/10.1080/13504622.2016.1250148?journalCode%3Dceer20&amp;sa=D&amp;source=editors&amp;ust=1684390025585211&amp;usg=AOvVaw2xmYX8WmlxvvyAVPahkyYG">feelings of guilt dissipate</a></span><span class="c7 c0">&nbsp;after the first behavior has been performed and this undermines motivation to engage in similar future behaviors. There is currently no research on guilt interventions in the context of AIs, but the risk of backfiring seems high given these previous findings. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">Even though interventions designed around contact, pre-existing attitudes, and core beliefs might be effective in inducing the transfer of moral consideration, to date there is no evidence for a long-term change in the moral consideration of AIs. So far, interventions have focused on short-term behavioral and contextual spillover. It is unknown whether these interventions have long-lasting effects on the moral consideration of AIs. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Another limitation of existing spillover research in the context of AIs is that the interventions conducted so far have been small-scale (i.e., small samples with limited types of AIs), often focused on non-moral</span><span>&nbsp;</span><span class="c7 c0">purposes (e.g., user experience), and disconnected from each other. Research on possible interventions with larger samples, for the purpose of studying moral spillover, and to track long-term effects (e.g., how moral consideration might transfer from current AIs to future AIs), would provide more insight into how spillover effects might facilitate or hinder the inclusion of AIs in the moral circle. </span></p><h1 class="c14 c48" id="h.jxrvu05vmabb"><span class="c24 c0 c18">What future research is needed?</span></h1><p class="c13 c14"><span class="c0">Research on moral spillover towards AIs is in its infancy. More empirical evidence is needed to understand how moral consideration may or may not</span><span>&nbsp;</span><span class="c7 c0">transfer from humans to AIs and from existing AIs to future AIs. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Future research should investigate how and when positive and negative attitudes and behaviors transfer to AIs, and the consequences this might have for their inclusion in the moral circle. Prosocial interactions&mdash;</span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/7451847&amp;sa=D&amp;source=editors&amp;ust=1684390025586502&amp;usg=AOvVaw3LHyT_yBjEAXc05FgvTlw3">real</a></span><span class="c0">&nbsp;or </span><span class="c25 c0"><a class="c2" href="https://www.google.com/url?q=https://ieeexplore.ieee.org/abstract/document/6926300&amp;sa=D&amp;source=editors&amp;ust=1684390025586830&amp;usg=AOvVaw0hh9BCBW8oL1uG1gs06j4e">imagined</a></span><span class="c0">&mdash;with individual robots have been shown to increase positive attitudes and behaviors towards similar and very different AIs. Developing this research in the moral domain with studies that examine precursors (e.g., pre-existing negative attitudes) to spillover could help us understand positive and negative attitude transfer and the potential backfiring effects of spillover interventions. This matters because interaction with AIs is likely to increase as they become more widespread in society. If</span><span>&nbsp;</span><span class="c7 c0">positive interactions with existing AIs facilitate moral consideration for AIs in general, future AIs might have a better chance of being included in the moral circle.</span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">How future AIs will appear, think, feel, and behave is uncertain. They are likely to have diverse mental capacities, goals, and appearances. Future AIs could range from highly human-like robots to non-embodied sentient algorithms or minuscule cell-like AIs. The mental capacities of AIs are likely to vary on a spectrum (e.g., from minimally sentient to more sentient than humans). How these diverse future AIs will be affected by moral spillover is unknown. Future research could examine whether there is a minimal threshold of similarity with humans that AIs must meet for moral consideration to transfer. Future studies could also examine whether the inclusion of even one kind of AI in the moral circle spills over to all AIs regardless of their features. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c7 c0">Furthermore, a neglected but important research direction is the examination of temporal spillover. A change in how AIs are treated in the present might shape the moral consideration of AIs in the future. One possible way of investigating temporal spillover would be to use longitudinal studies to examine how present attitudes and behaviors towards AIs affect attitudes and behaviors towards different future AIs. Further research on the effectiveness of interventions that change core beliefs towards AIs is likely also an important part of understanding temporal moral spillover. </span></p><p class="c4"><span class="c7 c0"></span></p><p class="c13 c14"><span class="c0">Expanding the research on moral spillover in the context of AIs has the potential to identify boundaries that shape human-AI interaction and the moral consideration of present AIs. Future research is also likely to broaden our understanding of how the many diverse AIs of the future will be extended moral consideration. Facilitating the transfer of moral consideration to AIs may be</span><span>&nbsp;</span><span class="c0">critical</span><span>&nbsp;</span><span class="c7 c0">to fostering a future society where the well-being of all sentient beings matters.</span></p><hr class="c40"><div><p class="c13 c14"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c27">&nbsp;</span><span class="c0 c15">See </span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://www.oah.org/tah/issues/2015/november/the-history-of-animal-protection-in-the-united-states/&amp;sa=D&amp;source=editors&amp;ust=1684390025588151&amp;usg=AOvVaw0lK6iBHe_rUeONcQF9exo8">Davis (2015)</a></span><span class="c0 c15">&nbsp;and </span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://faunalytics.org/the-animal-rights-movement-history-and-facts-about-animal-rights/&amp;sa=D&amp;source=editors&amp;ust=1684390025588521&amp;usg=AOvVaw1d5TbFkmpLMnliJYlwF8wJ">Orzechowski (2020)</a></span><span class="c11 c0 c26">&nbsp;for more on the histories of the animal rights and anti-slavery social movements.</span></p></div><div><p class="c13 c14"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c27">&nbsp;</span><span class="c0 c15">In humans and animals, sentience is usually defined as the capacity to have positive and negative experiences, such as happiness and suffering. However, we understand that sentience does not necessarily have to look the same in AIs. We outline how one might assess sentience in AIs in a </span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://www.sentienceinstitute.org/blog/assessing-sentience-in-artificial-entities&amp;sa=D&amp;source=editors&amp;ust=1684390025591911&amp;usg=AOvVaw39DgsVCaHLQPulO3GJ6SkC">previous post</a></span><span class="c26 c11 c0">. </span></p></div><div><p class="c13 c14"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c0 c15">&nbsp;We take the view that the well-being of an entity </span><span class="c0 c15"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Animal_Liberation_(book)&amp;sa=D&amp;source=editors&amp;ust=1684390025592392&amp;usg=AOvVaw3EW89Z0TpQGrT8RbQuUQTW">is tied to</a></span><span class="c0 c15">&nbsp;judgments of </span><span class="c0 c15"><a class="c2" href="https://www.google.com/url?q=https://forum.effectivealtruism.org/topics/moral-patienthood&amp;sa=D&amp;source=editors&amp;ust=1684390025592702&amp;usg=AOvVaw33GqHXaIxnpIPSdyOzzuYV">moral patiency</a></span><span class="c0 c15">, as opposed to </span><span class="c0 c15"><a class="c2" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Moral_agency&amp;sa=D&amp;source=editors&amp;ust=1684390025592985&amp;usg=AOvVaw0VqWb02kIGJClaesaN0nTr">moral agency</a></span><span class="c0 c15">. Whether an AI is able to discern right from wrong, how the AI acts or how the AI is programmed </span><span class="c0 c15"><a class="c2" href="https://www.google.com/url?q=https://link.springer.com/article/10.1007/s10676-020-09540-4&amp;sa=D&amp;source=editors&amp;ust=1684390025593279&amp;usg=AOvVaw3g7RHjcGoYEsi1vKvuYs3n">does not necessarily change</a></span><span class="c26 c11 c0">&nbsp;whether or not they should be considered a moral patient. That is, even if an AI who does not care about moral treatment is developed, we still ought to treat them morally on the basis that they are a moral patient.</span></p></div><div><p class="c13 c14"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c27">&nbsp;</span><span class="c0 c15">Moral spillover can also occur for the opposite of moral consideration (e.g., actively wishing harm upon someone). Negative moral spillover has been referred to as </span><span class="c0 c15 c6">moral taint</span><span class="c26 c11 c0">.</span></p></div><div><p class="c13 c14"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c11 c0">&nbsp;</span><span class="c0 c15">From a psychological perspective, t</span><span class="c11 c0">he term &ldquo;</span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://dictionary.apa.org/prosocial&amp;sa=D&amp;source=editors&amp;ust=1684390025589044&amp;usg=AOvVaw1hQ37U9JWqsyAbjkm5NFfy">prosocial</a></span><span class="c11 c0">&rdquo; refers to a behavior that benefits one or more other beings (e.g., offering one&rsquo;s seat to an</span><span class="c0 c15">&nbsp;older</span><span class="c11 c0">&nbsp;person on a bus).</span><span class="c0 c15">&nbsp;T</span><span class="c11 c0">he term &ldquo;</span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://dictionary.apa.org/moral&amp;sa=D&amp;source=editors&amp;ust=1684390025589463&amp;usg=AOvVaw0oY-A-AguknAE-OgR5hrBs">moral</a></span><span class="c11 c0">&rdquo; refers to a behavior that is ethical or proper (e.g., right or wrong). </span><span class="c0 c15">These terms can overlap</span><span class="c11 c0">. A prosocial behavior can in some cases also be a moral behavior (an</span><span class="c0 c15">d vice versa)</span><span class="c11 c0">, insofar as both kinds of actions promote the interests of other beings and can be construed as right or wrong. Given that </span><span class="c0 c15">much </span><span class="c26 c11 c0">of the moral spillover research in HRI is framed as the study of prosocial behavior, we use the terms &ldquo;moral&rdquo; and &ldquo;prosocial&rdquo; interchangeably.</span></p></div><div><p class="c13 c14"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c0 c11">&nbsp;</span><span class="c0 c15">T</span><span class="c11 c0">emporal spillover </span><span class="c0 c15">could include a huge range of attitudes and behavior, such as simply having one attitude persist over time (e.g., after seeing a compelling fundraiser for a charity, you still feel compelled two weeks later). A narrower definition of spillover would exclude situations where moral consideration merely transfers to the same individual or group at a different time, rather than to different entities</span><span class="c11 c0">.</span></p></div><div><p class="c13 c14"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c0 c15">&nbsp;See </span><span class="c1 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12419&amp;sa=D&amp;source=editors&amp;ust=1684390025590804&amp;usg=AOvVaw3dy_ysO9cqKn86x52RHNar">Boin et al. (2021)</a></span><span class="c0 c15">&nbsp;and </span><span class="c25 c0 c15"><a class="c2" href="https://www.google.com/url?q=https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-071620-030619&amp;sa=D&amp;source=editors&amp;ust=1684390025591127&amp;usg=AOvVaw3xX2m2h_JOzqhgPRBFdmp6">Paluck et al. (2021)</a></span><span class="c26 c11 c0">&nbsp;for recent reviews of the effectiveness of contact interventions.</span></p></div></body></html>
