<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_3uunq6pfukj6-5{list-style-type:none}ul.lst-kix_3uunq6pfukj6-6{list-style-type:none}ul.lst-kix_3uunq6pfukj6-7{list-style-type:none}ul.lst-kix_3uunq6pfukj6-8{list-style-type:none}ul.lst-kix_3uunq6pfukj6-1{list-style-type:none}ul.lst-kix_3uunq6pfukj6-2{list-style-type:none}ul.lst-kix_3uunq6pfukj6-3{list-style-type:none}ul.lst-kix_3uunq6pfukj6-4{list-style-type:none}ul.lst-kix_idz1luao3viv-5{list-style-type:none}ul.lst-kix_idz1luao3viv-4{list-style-type:none}ul.lst-kix_idz1luao3viv-7{list-style-type:none}ul.lst-kix_3uunq6pfukj6-0{list-style-type:none}ul.lst-kix_idz1luao3viv-6{list-style-type:none}ul.lst-kix_idz1luao3viv-1{list-style-type:none}ul.lst-kix_idz1luao3viv-0{list-style-type:none}ul.lst-kix_idz1luao3viv-3{list-style-type:none}ul.lst-kix_idz1luao3viv-2{list-style-type:none}.lst-kix_3uunq6pfukj6-0>li:before{content:"\0025cf  "}.lst-kix_idz1luao3viv-2>li:before{content:"\0025a0  "}.lst-kix_idz1luao3viv-3>li:before{content:"\0025cf  "}.lst-kix_3uunq6pfukj6-1>li:before{content:"\0025cb  "}.lst-kix_3uunq6pfukj6-2>li:before{content:"\0025a0  "}.lst-kix_idz1luao3viv-0>li:before{content:"\0025cf  "}.lst-kix_idz1luao3viv-1>li:before{content:"\0025cb  "}.lst-kix_3uunq6pfukj6-8>li:before{content:"\0025a0  "}.lst-kix_3uunq6pfukj6-7>li:before{content:"\0025cb  "}.lst-kix_3uunq6pfukj6-6>li:before{content:"\0025cf  "}.lst-kix_3uunq6pfukj6-4>li:before{content:"\0025cb  "}.lst-kix_idz1luao3viv-6>li:before{content:"\0025cf  "}.lst-kix_3uunq6pfukj6-3>li:before{content:"\0025cf  "}.lst-kix_3uunq6pfukj6-5>li:before{content:"\0025a0  "}.lst-kix_idz1luao3viv-4>li:before{content:"\0025cb  "}.lst-kix_idz1luao3viv-5>li:before{content:"\0025a0  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_idz1luao3viv-8{list-style-type:none}.lst-kix_idz1luao3viv-7>li:before{content:"\0025cb  "}.lst-kix_idz1luao3viv-8>li:before{content:"\0025a0  "}ol{margin:0;padding:0}table td,table th{padding:0}.c15{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c10{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c16{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c1{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial"}.c4{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c11{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c14{margin-left:36pt;padding-left:0pt}.c17{padding:0;margin:0}.c12{color:inherit;text-decoration:inherit}.c19{width:33%;height:1px}.c5{font-size:10pt}.c13{font-size:20pt}.c8{height:11pt}.c6{font-weight:700}.c0{font-style:italic}.c18{font-size:16pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c11"><p class="c3"><span class="c0">Edited by Kelly Witwicki. Many thanks to Oliver Austin, Antonin Broi, Guillaume Corlouer, Peter Hurford, Tyler John, Caleb Ontiveros, Jay Quigley, Jose Luis Ricon, Brian Tomasik, and Jay Quigley for reviewing and providing feedback.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>We launched Sentience Institute in June 2017 &ldquo;to build on the body of evidence for how to most effectively expand humanity&rsquo;s moral circle, and to encourage advocates to make use of that evidence.&rdquo; Our aim is to expand the moral circle to include all sentient beings, but the term </span><span class="c0">sentience</span><span class="c2">&nbsp;opens up a host of important philosophical and empirical questions about exactly which beings we&rsquo;re talking about.</span></p><h1 class="c15" id="h.qdc935s9p5hp"><span class="c7 c13">Most of what we do doesn&rsquo;t depend on the specifics.</span></h1><p class="c3"><span>Sentience Institute&rsquo;s current focus is on expanding humanity&rsquo;s moral circle to include farmed animals like chickens, fish, cows, and pigs. Our survey results suggest that 87% of US adults agree that &ldquo;Farmed animals have roughly the same ability to feel pain and discomfort as humans.&rdquo;</span><sup><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span>&nbsp;Presumably an even higher percentage would agree that they have at least some level of sentience. </span><span>There also seems to be consensus in the field of neuroscience that there is strong evidence for the sentience of many nonhuman animals.</span><sup><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span class="c2">This suggests that most common definitions and theories of consciousness agree that expanding the moral circle to all sentient beings includes expanding it to farmed animals, with perhaps an exception for the farmed animals with the simplest nervous systems such as shellfish and insects.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>If we had to commit Sentience Institute as an organization to a single definition of sentience, we would say it&rsquo;s simply </span><span class="c6">the </span><span class="c6">capacity</span><span class="c6">&nbsp;to have </span><span class="c6">positive and negative</span><span class="c6">&nbsp;experiences</span><span>, usually thought of as happiness and suffering</span><span>.</span><sup><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span>&nbsp;</span><span>This is </span><span>narrower</span><span>&nbsp;than the most common definition of consciousness</span><span>&nbsp;in philosophy</span><span>, which is </span><span>&ldquo;something it is like to be that organism</span><span>&rdquo;</span><span>&nbsp;(details in the second section of the post). Usually </span><span>the term </span><span class="c0">consciousness</span><span>&nbsp;includes capacities beyond happiness and suffering, such as the experiences of </span><span>seeing or visualizing </span><span>a</span><span>&nbsp;color</span><span>. Sentience Institute chose to focus on sentience, which is a specific kind of consciousness,</span><span>&nbsp;</span><span>because</span><span>&nbsp;most people</span><span>&nbsp;who have given significant thought to the topic</span><span>&nbsp;see sentience as morally relevant, </span><span>rather than </span><span>all conscious</span><span>&nbsp;experience</span><span>.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>There are numerous theories of what exactly </span><span>consciousness</span><span>&nbsp;is. Is consciousness just a </span><span>set of processes</span><span>&nbsp;(</span><span class="c0">functionalism</span><span>)? </span><span>Is it behavior (</span><span class="c0">behaviorism</span><span>)</span><span>? </span><span>E</span><span>tc. There is substantial </span><span class="c4"><a class="c12" href="https://www.google.com/url?q=https://www.edge.org/conversation/five-problems-in-the-philosophy-of-mind&amp;sa=D&amp;source=editors&amp;ust=1648306838872165&amp;usg=AOvVaw26xYdO1yFM2pfwiaORoW4r">disagreement</a></span><span>&nbsp;among researchers on which theory is most likely correct</span><span>, and in fact there is</span><span>&nbsp;disagreement about whether there is an objectively correct answer</span><span>,</span><span>&nbsp;</span><span>as intuition suggests</span><span>&nbsp;</span><span>(the second part of this blog post </span><span>will argue that</span><span>&nbsp;there is </span><span>not</span><span>)</span><span class="c2">.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>While we are always ready to update our beliefs on this matter, f</span><span>or now we think there&rsquo;s </span><span>significant evidence </span><span>relative to </span><span>these perspectives </span><span>that nonhuman animals as simple as shrimp and insects have at least a small level of sentience or a small probability of sentience. This suggests they deserve much more moral consideration than they receive today, and thus we need </span><span>to </span><span>substantial</span><span>ly</span><span>&nbsp;expan</span><span>d</span><span>&nbsp;humanity&rsquo;s moral circle to </span><span>include </span><span>an extremely large number of beings</span><span>.</span><span>&nbsp;</span><span>This position is</span><span>&nbsp;all we need for most of our organizational decisions at Sentience Institute</span><span>,</span><span>&nbsp;at least for now.</span></p><h1 class="c15" id="h.epn00ihr0vjn"><span>T</span><span class="c7 c13">entative views on the nature of sentience and consciousness</span></h1><p class="c3"><span class="c0">Update: March 26, 2022. The following section of this blog post has been superseded by a new paper on consciousness, a non-paywalled version of which is available </span><span class="c4 c0"><a class="c12" href="https://www.google.com/url?q=https://jacyanthis.com/Consciousness_Semanticism.pdf&amp;sa=D&amp;source=editors&amp;ust=1648306838873268&amp;usg=AOvVaw1-DbJx0LdpvBd82gLa2iCj">here</a></span><span class="c0">. Please cite as: Anthis, Jacy Reese. 2022. &ldquo;Consciousness Semanticism: A Precise Eliminativist Theory of Consciousness.&rdquo; In Biologically Inspired Cognitive Architectures 2021, edited by Valentin Klimov and David Kelley, 1032:20&ndash;41. Studies in Computational Intelligence. Cham: Springer International Publishing. </span><span class="c4 c0"><a class="c12" href="https://www.google.com/url?q=https://doi.org/10.1007/978-3-030-96993-6_3&amp;sa=D&amp;source=editors&amp;ust=1648306838873464&amp;usg=AOvVaw2ix7R57_4TZzQ0OQ9x5_Jy">https://doi.org/10.1007/978-3-030-96993-6_3</a></span><span class="c0 c20">.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>I&rsquo;ve personally given a lot of thought to this topic even before co-founding Sentience Institute, so I&rsquo;d like to spend the rest of this blog post detailing my current views, even though we&rsquo;re not yet willing to commit the organization to a philosophical position on the topic.</span><span>&nbsp;We hesitate to adopt an organizational view given such strong disagreement among researchers on the topic, but finding the correct answer here could substantially impact our research decisions and strategic views, so we would like to explore it more in the long run.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>My overall tentative view is this: Consciousness (including sentience) does not exist </span><span>in the common-sense </span><span>way people intuitively believe it does. </span><span>Specifically, we cannot merely discover whether a being is conscious &mdash; a possibility which is implied by popular questions like, &ldquo;Is this robot conscious?&rdquo; &mdash; like we might be able to discover whether an atom is gold or silver, based precisely on its atomic number.</span><span>&nbsp;</span><span>(Of course we can create a precise definition that allows us to determine this for consciousness, as I will elaborate on later, but current definitions are insufficient to allow for the categorization of entities as conscious or not.)</span><span>&nbsp;People may have an intuition that consciousness </span><span>is a</span><span>&nbsp;real, substantive (or other similar terms) thing in the universe, but I think that intuition is unreliable and ultimately mistaken.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>The view I wish to defend is often referred to as </span><span class="c0">eliminative materialis</span><span class="c0">m</span><span>, defined by</span><span>&nbsp;the Stanford Encyclopedia of Philosophy as: &ldquo;Our ordinary, common-sense understanding of the mind is deeply wrong and that some or all of the mental states posited by common-sense do not actually exist.&rdquo;</span><span>&nbsp;I believe Brian Tomasik has written the best articulation and defense of this view in his essay, </span><span class="c4"><a class="c12" href="https://www.google.com/url?q=https://foundational-research.org/the-eliminativist-approach-to-consciousness/&amp;sa=D&amp;source=editors&amp;ust=1648306838874349&amp;usg=AOvVaw2tOISL2C59613G5dRemlFz">&ldquo;The Eliminativist Approach to Consciousness.&rdquo;</a></span><span>&nbsp;We seem to agree on essentially all the details, though I think we approach the topic with different focuses and terminology.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>I&rsquo;m also fine with the term </span><span class="c0">consciousness reductionist</span><span>,</span><span>&nbsp;and I think the difference between this and eliminativism is semantic, or at least only a matter of rhetorical strategy. </span><span>Consciousness reductionism is the idea that we</span><span>&nbsp;can reduce consciousness to other phenomena, </span><span>and eliminativism means </span><span>we can just leave out discussion of consciousness and simply refer to those other phenomena. It might be advantageous in our discussions to use one of these framings over the other, but to the best of my knowledge, </span><span>they both communicate the same empirical view of the universe</span><span class="c2">.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>I</span><span>&nbsp;also</span><span>&nbsp;endorse </span><span class="c0">illusionism</span><span>, </span><span>meaning </span><span>consciousness is an illusion like stage magic is an illusion, though I prefer not to use this term when possible because it doesn&rsquo;t seem </span><span>very </span><span>well-defined to me</span><span>.</span><span>&nbsp;I use the term sometimes because it&rsquo;s a useful intuitive way of gesturing at my precise views</span><span>, and this is the </span><span class="c4"><a class="c12" href="https://www.google.com/url?q=https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood&amp;sa=D&amp;source=editors&amp;ust=1648306838875107&amp;usg=AOvVaw335G7YUJm8Jl5eafL3odYy">preferred terminology</a></span><span>&nbsp;of Luke Muehlhauser at Open Philanthropy Project.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>In </span><span>philosopher David </span><span>Chalmers&rsquo; </span><span class="c4"><a class="c12" href="https://www.google.com/url?q=http://consc.net/papers/nature.html&amp;sa=D&amp;source=editors&amp;ust=1648306838875468&amp;usg=AOvVaw2GehnIrvSXQoR9TWNZyfpx">popular framework</a></span><span>&nbsp;of views on consciousness, I identify as a </span><span class="c0">type-A materialist</span><span>&nbsp;or a </span><span class="c0">type-A physicalist</span><span>. This means I don&rsquo;t believe there&rsquo;s a </span><span class="c0">hard problem</span><span>&nbsp;of consciousness. I</span><span>n other words, I</span><span>&nbsp;believe </span><span>&ldquo;there is no epistemic gap between physical and phenomenal truths</span><span>; or at least, any apparent epistemic gap is easily closed.&rdquo;</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Finally, I&rsquo;m a </span><span class="c0">consciousness denier</span><span>, though it&rsquo;s important to clarify that I&rsquo;m not denying that I have first-person experiences of the world. </span><span>I am fully on board with, &ldquo;I think, therefore I am,&rdquo; and the notion that you can have 100% confidence in your own first-person experience</span><span>. </span><span>What</span><span>&nbsp;I reject </span><span>is </span><span>the existence of a</span><span>ny</span><span>&nbsp;broader set of things in the universe that we can objectively refer to as consciousness, based on standard</span><span>, vague</span><span>&nbsp;definitions like &ldquo;something it is like to be that organism</span><span>&rdquo; or our intuitions and first-person experiences.</span><span>&nbsp;I don&rsquo;t think consciousness is an </span><span>objective</span><span>&nbsp;(i.e. attitude-independent)</span><span>&nbsp;reality</span><span class="c2">&nbsp;in this intuitive sense.</span></p><h2 class="c1" id="h.k0g8iv3is1ar"><span class="c7 c18">The core argument for eliminativism</span></h2><p class="c3"><span>With any of the common definitions of consciousness, </span><span>I&rsquo;m</span><span>&nbsp;an eliminativist. </span><span>The most common three definitions (or at least ways of pointing to consciousness) are</span><span class="c2">:</span></p><p class="c3 c8"><span class="c2"></span></p><ul class="c17 lst-kix_idz1luao3viv-0 start"><li class="c3 c14 li-bullet-0"><span class="c2">&ldquo;Something that it is like for the organism to be itself&rdquo;</span></li><li class="c3 c14 li-bullet-0"><span>&quot;</span><span>I</span><span>f you have to ask, you&rsquo;ll never know</span><span>.</span><span>&quot;</span><sup><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup></li><li class="c3 c14 li-bullet-0"><span>A deictic definition using personal examples, such as saying, &ldquo;It&rsquo;s the common feature between seeing the color red, imagining the shape of a triangle, and feeling the emotion of joy.</span><span>&rdquo;</span></li></ul><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>But all of these (and other definitions, especially circular ones that just define consciousness with reference to another vague concept like &ldquo;awareness&rdquo;</span><sup><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span>) share a fatal issue &mdash; they lack precision. They are insufficient for me to write a computer program that takes all objects in the universe and categori</span><span>z</span><span>es them as conscious or nonconscious.</span><span>&nbsp;Contrast this with</span><span>&nbsp;a precise definition like, &ldquo;An even number is an integer which is a multiple of two.&rdquo;</span><span>&nbsp;I could easily write a computer program</span><span>&nbsp;(assuming I have sufficient programming skill and a sufficiently powerful computer)</span><span>&nbsp;that takes any integer and divides it by two. If the result is an integer, it is even. If the result is not an integer, it is not even.</span><span>&nbsp;(And if </span><span>the original number is</span><span>&nbsp;not even an integer, then of course it&rsquo;s not an even number.) Thus the definition of </span><span>even</span><span class="c2">&nbsp;is precise for all integers.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>So with a </span><span>seemingly </span><span>common-sense question like, &ldquo;Is an insect conscious?&rdquo; we can&rsquo;t discover an answer even with the very best neuroscience, philosophy, and all other knowledge about the universe</span><span>, because we do not have a precise definition of consciousness</span><span>.</span><sup><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span>&nbsp;</span><span>This is the same way we would struggle to answer, &ldquo;Is a virus alive?&rdquo; We can&rsquo;t hope to find an answer, or even give a probability, to these questions without giving a new, more exact definition of the term. </span><span>Maybe we could define </span><span class="c0">alive</span><span>&nbsp;as &ldquo;able to reproduce,&rdquo;</span><span>&nbsp;(of course, an oversimplification)</span><span>&nbsp;then assuming we&rsquo;re on the same page with the definition of </span><span class="c0">reproduce</span><span>, I could probably (in theory) write a computer program that categorizes everything in the universe into &ldquo;alive&rdquo; and &ldquo;not alive</span><span>.</span><span>&rdquo;</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>This issue is a straightforward </span><span>consequence of any imprecise definition</span><span>&nbsp;&mdash; let&rsquo;s call it the </span><span class="c6">imprecision argument</span><span>&nbsp;in favor of eliminativism &mdash; </span><span>yet scientists, philosophers, and others frequently throw out questions like &ldquo;Is an insect conscious?&rdquo; with the expectation that we might be able to one day discover an answer to this question</span><span>, which is simply not possible if we don&rsquo;t have criteria in place to evaluate whether an insect is conscious</span><span>.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>To be clear, I don&rsquo;t think people who believe consciousness exists (i.e. people who disagree with me here) are just mistaken about how hard the question is or that they&rsquo;re underestimating the resources it would take to answer that question. </span><span>Instead, I&rsquo;m arguing that questions like, &ldquo;Is an insect conscious?&rdquo; are actually impossible to answer.</span><span>&nbsp;This is different than, say, math &mdash; where questions like &ldquo;What is 32985 times 54417?&rdquo; are hard, but not impossible to answer, especially given certain technologies like handheld calculators.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>W</span><span>e can&rsquo;t expect that sort of conclusive answer with consciousness because we can&rsquo;t say exactly what it would mean for the insect to be conscious</span><span>, like we can say a square root of a number is a number that, when multiplied by itself, gives the original number</span><span>.</span><span>&nbsp;It might be very clear </span><span>to you </span><span>that you yourself are conscious &mdash; if we&rsquo;re using a deictic definition &mdash; but that doesn&rsquo;t speak at all to whether a virus, an insect, or </span><span>even another human</span><span>&nbsp;is conscious.</span><sup><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup></p><h3 class="c10" id="h.eztm4yo33y8t"><span class="c16">Objections</span></h3><p class="c3"><span class="c6">&ldquo;We have some positive examples of consciousness (e.g. adult, </span><span class="c6">awake </span><span class="c6">humans</span><span class="c6">) and some negative examples (e.g. rocks). Therefore, we can make arguments by analogy about whether other objects are conscious based on the features they share with these examples.&rdquo;</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>First, how do you really know those are valid examples? What in the definition of consciousness allows you to conclude anything about any of those objects &mdash; except for your own consciousness, alone, if you use the deictic definition?</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Second, the existence of examples doesn&rsquo;t by itself allow you to make estimates of other objects. This is only possible in cases where you know there&rsquo;s an underlying, objective definition and are simply making estimates of that definition. For example, if I show you 10 shapes on a standardized test that are &ldquo;nice&rdquo; and 10 shapes that I say are not &ldquo;nice,&rdquo; then you can make an educated guess about whether another shape is &ldquo;nice&rdquo; based on the features it shares with the positive and negative examples. But you can only do that because there&#39;s an implication that I have some objective definition I&#39;m using behind the curtains to know if shapes are nice.</span><span>&nbsp;With consciousness, </span><span>I see no reason to believe there&rsquo;s such a behind-the-curtains definition</span><span>&nbsp;that exists but just hasn&rsquo;t been told to you yet</span><span>, despite how common usage of the term suggests there is one</span><span>.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span class="c6">&ldquo;Okay, sure, consciousness isn&rsquo;t objective in that sense. But neither is an everyday term like, say, </span><span class="c6 c0">mountain</span><span class="c6">. Are we supposed to stop saying </span><span class="c6 c0">mountain</span><span class="c6">&nbsp;because not everyone agrees on a precise definition?&rdquo;</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Of course not. The term </span><span class="c0">mountain</span><span>&nbsp;is useful because our everyday discussions don&rsquo;t depend on fine granularity. When I ask, &ldquo;Is there a mountain in New York City?&rdquo; you can intelligently</span><sup><a href="#ftnt8" id="ftnt_ref8">[8]</a></sup><span>&nbsp;respond that no, there is no mountain. But if I ask you, &ldquo;Is there a mountain in San Francisco?&rdquo; then you might need to clarify how tall a peak must be to qualify as a mountain because Mount Davidson, at 282 meters above sea level, </span><span>may or may not make the cut</span><span class="c2">.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>The issue with consciousness is that our definitions </span><span>(e.g. &ldquo;what it is like to be&rdquo;) </span><span>are not nearly precise enough to match </span><span>common usage</span><span>&nbsp;(the implication that there&rsquo;s an objective, discoverable answer)</span><span>. </span><span>When someone asks, &ldquo;Is this robot conscious?&rdquo; in 2030, we might very well be dealing with a Mount Davidson situation.</span><span>&nbsp;</span><span>So we need a more precise definition in order to provide a reasonable answer. </span><span>And getting that precise definition isn&rsquo;t a process of discovery any more than it&rsquo;s a process of discovery to decide the cutoff for mountain height &mdash; it&rsquo;s a process of making up a definition, perhaps bas</span><span>ed on convenience or </span><span>trying to get as close as possible to </span><span>people</span><span>&rsquo;s intuitions</span><span>.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>T</span><span>o reiterate, I&rsquo;m not denying that your first-person experience exists</span><span>&nbsp;any more than I&rsquo;m denying that Mount Davidson (or any other set of atoms that we speak of, like Mount Everest or Mount Diablo) exists</span><span>. I&rsquo;m just denying that a vague definition of </span><span class="c0">mountain</span><span>&nbsp;would </span><span>let us identify every mountain and non-mountain</span><span>&nbsp;in the universe, just as our vague definitions of consciousness don&rsquo;t </span><span>let us identify every conscious and non-conscious entity even with all the scientific tools and knowledge we can imagine</span><span>. </span><span>So I am a </span><span class="c0">mountainhood eliminativist</span><span>&nbsp;(i.e. </span><span class="c0">mountainhood anti-realist</span><span>)</span><span>&nbsp;&mdash; I don&rsquo;t think we could possibly discover whether certain peaks are mountains given that there&rsquo;s not a precise definition of mountains. </span><span>This </span><span>might be</span><span>&nbsp;unintuitive, but per the arguments above, it seems entirely correct to me.</span><sup><a href="#ftnt9" id="ftnt_ref9">[9]</a></sup><span>&nbsp;If someone decided to open a line of scientific inquiry dedicated to finding out whether or not certain peaks are mountains, I don&rsquo;t think they could succeed or make any progress on that question in itself because they don&#39;t have a definition to guide their inquiry. Of course, if you presupposed a cutoff for mountain height, such as 300 meters, or even a range of cutoffs over which we&rsquo;re uncertain, such as 200 to 400 meters, then I&rsquo;d be much closer to </span><span class="c0">mountainhood realism</span><span>.</span><sup><a href="#ftnt10" id="ftnt_ref10">[10]</a></sup></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>I think this same argument applies to all imprecise </span><span>terms</span><span>, such as terms for elements like gold and silver before humans had a precise definition of these elements (i.e. their atomic numbers)</span><span>.</span><sup><a href="#ftnt11" id="ftnt_ref11">[11]</a></sup><span>&nbsp;</span><span>It also applies to moral properties that serve as &ldquo;useful fictions&rdquo; like freedom and honor, b</span><span>ut I&rsquo;m not planning to write blog posts railing against the </span><span>way people use those terms. With a question like &ldquo;Is a citizen in a high-surveillance democracy free?&rdquo; people tend to recognize that, while science and logic can inform our answer, we cannot find an objective answer without a more precise definition &mdash; some baseline of what exactly &ldquo;free&rdquo; means. This is unlike discussions of</span><span>&nbsp;&ldquo;consciousness&rdquo; and &ldquo;sentience,&rdquo; where </span><span>I</span><span class="c2">&nbsp;see a lot of wasted resources spent on and moral decisions based on these properties being discoverable.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span class="c6">&ldquo;That&rsquo;s an interesting argument that consciousness doesn&rsquo;t exist. But I have a better argument that consciousness exists. In fact, I have first-person experience that consciousness exists. This is superior to any logical or empirical argument.&rdquo;</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>I&rsquo;m not denying your first-person experience</span><span>. </span><span>Your first-person experience is an interesting and important feature of the world</span><span>. If that&rsquo;s all you mean when you argue consciousness exists, then I&rsquo;m in full agreement. But usually people think of consciousness as a broader set of things in the world that is at least happening in the brains of billions of humans, if not also in many nonhuman animals. </span><span>That broader set is not something of which you (or I) could possibly have first-person experiences, unless you&rsquo;re suggesting some kind of mental connection between you and all of those other beings that enables you to experience their experiences.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span class="c2">But I am sympathetic to the strong intuition felt by many people that the broader set exists. I&rsquo;ve felt that intuition too! However, I&rsquo;ve since cast it off for two reasons.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>First, I don&rsquo;t think humans have reliable intuitions about this kind of deep question. Humans didn&rsquo;t evolve making judgments of and getting feedback on our answers to deep questions like the nature of sentience, quantum physics, molecular biology, or any other field that wasn&rsquo;t involved in the day-to-day life of our distant ancestors. And you probably haven&rsquo;t had the opportunity to develop reliable intuitions to deep </span><span>questions</span><span class="c2">&nbsp;during your lifetime, though if you&rsquo;ve spent years studying philosophy or similar disciplines, then perhaps you&rsquo;ve developed some decent intuitions on these topics.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Second, I think there&rsquo;s good reason to expect us to have an intuition that consciousness exists even if that&rsquo;s not true. The idea of an objective property of consciousness is in line with a variety of intuitions humans have about their own superiority and special place in the universe. We tend to underestimate the mental capacities of nonhuman animals; we struggle to accept our own inevitable deaths; and even with respect to other humans, most of us suffer from the </span><span>Dunning&ndash;Kruger</span><span>&nbsp;effect: We believe our cognitive ability is better than it actually is. </span><span>Consciousness realism is the same sort of phenomenon: it places our mental lives in a distinct, special category, which is something we strongly desire, but a desire for something to be true doesn&rsquo;t make it true!</span></p><h3 class="c10" id="h.6auw1enj3fbr"><span class="c16">Moving forward with sentience research.</span></h3><p class="c3"><span>My view here fortunately</span><sup><a href="#ftnt12" id="ftnt_ref12">[12]</a></sup><span>&nbsp;doesn&rsquo;t curtail the development of a deeper understanding of sentience or consciousness, </span><span>nor does it curtail our ability to make progress on better understanding exactly which beings should be included in our moral circles.</span><span class="c2">&nbsp;In fact, it facilities this. If we&rsquo;re stuck on consciousness being a real phenomenon, we&rsquo;ll tend to waste a ton of effort musing about its existence or directly looking for it in the universe.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>There&rsquo;s an unfortunate cyclical effect here: our misguided intuition fuels vague terminology and causes philosophers and scientists to work hard to justify that intuition &mdash; as they have for centuries &mdash; which then enables a continuation of that misguided intuition. </span><span>I believe that if we can get past this mental roadblock and accept the imprecision of our current terminology</span><span>, accept that there is no objective truth to consciousness as it&rsquo;s currently defined, then we can make meaningful progress on the two questions that are actually very real and important: </span><span>What exactly are the features of various organisms and artificial beings, and which exact features do we morally care about?</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>If we want to call those features, or some other set of features, &ldquo;sentience,&rdquo; that could be similar to, though not as elegant as, the way we started using &ldquo;gold&rdquo; to refer to an element with a certain atomic number that roughly mapped onto the proto-scientific vague definition of &ldquo;gold.&rdquo; But we could also drop the term, the way we&rsquo;ve eliminated &ldquo;</span><span class="c0">&eacute;lan vital</span><span>&rdquo; in favor of discussing specific biological features.</span><span class="c2">&nbsp;I don&rsquo;t have a strong view on the best rhetorical strategy.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Cataloguing mental features and refining our moral views on them might be a project</span><span>&nbsp;Sentience Institute tackles in the future,</span><sup><a href="#ftnt13" id="ftnt_ref13">[13]</a></sup><span>&nbsp;though as stated earlier, it seems we have a good enough understanding of them right now for the purpose of advocating for the rights and welfare of farmed animals, wild animals, and artificial beings if they are at some point </span><span>evaluated to be sentient (defined via moral concern)</span><span>. Even in the case of artificial sentience, we don&rsquo;t need to have an exact understanding of the features sentient artificial beings will have in order to advocate on their behalf. Because our moral circle is currently very restrictive, advocating for its expansion gets us closer to the proper size, even if we&rsquo;re not sure exactly what that is</span><span>.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>There are also two important implications of eliminativism outside of sentience research. First, it reduces the likelihood of moral convergence because one way moral convergence can happen is if humanity discovers which beings are sentient and that serves as our criterion for moral consideration. This then should makes us more pessimistic about the expected moral value of the far future given humanity&rsquo;s continued existence, which then makes reducing extinction risk a </span><span class="c4"><a class="c12" href="https://www.google.com/url?q=http://effective-altruism.com/ea/1l0/why_i_prioritize_moral_circle_expansion_over/&amp;sa=D&amp;source=editors&amp;ust=1648306838882792&amp;usg=AOvVaw1HB31myCl33puZJqyYl-aj">less promising strategy</a></span><span class="c2">&nbsp;for doing good.</span></p><p class="c3 c8"><span class="c2"></span></p><p class="c3"><span>Second, it seems to usually increase the moral weight people place on small and weird minds, such as insects and simple artificial beings. This is because when you see sentience as a discoverable, real property in the world, you tend to care about all features of various beings (neuophysiology, behavior, but also physical appearance, evolutionary distance from humans, substrate, etc.) because these are all analogical evidence of sentience. However, if you see sentience as a vague property that&rsquo;s up to us to specify, then you tend to care less about the features that seem less morally relevant in themselves (e.g. physical appearance, evolutionary distance). If an insect has the capacity for reinforcement learning, moods like anxiety, and integration of mental processes, then the eliminativist is more free to just say, &ldquo;Okay, that&rsquo;s a being I care about. My moral evaluation could change based on more empirical evidence, but those mental features are things I want to include as some level of sentience.&rdquo; In other words, eliminativism places a burden on people who want to deny animal sentience. They more need to point to a specific, testable mental feature that those animals lack.<br><br>These implications of the eliminativism question make me see it as one of the most important theoretical questions in Sentience Institute&rsquo;s purview.</span></p><hr class="c19"><div><p class="c9"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c5">&nbsp;</span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=https://www.sentienceinstitute.org/animal-farming-attitudes-survey-2017&amp;sa=D&amp;source=editors&amp;ust=1648306838883250&amp;usg=AOvVaw0Y9FeT2euiuDGY7yOd6bXd">https://www.sentienceinstitute.org/animal-farming-attitudes-survey-2017</a></span></p><p class="c9"><span class="c5">Another survey: </span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=http://cratefreefuture.com/pdf/American%252520Farm%252520Bureau-Funded%252520Poll.pdf&amp;sa=D&amp;source=editors&amp;ust=1648306838883471&amp;usg=AOvVaw2jWDy2JBvpos_crWx6CkDy">http://cratefreefuture.com/pdf/American%2520Farm%2520Bureau-Funded%2520Poll.pdf</a></span></p></div><div><p class="c9"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c5">&nbsp;See, for example, </span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf&amp;sa=D&amp;source=editors&amp;ust=1648306838883720&amp;usg=AOvVaw28qkKwflaMzbFcNs9o4RVf">http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf</a></span></p></div><div><p class="c9"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c5">&nbsp;Other terms to refer to these experiences are &ldquo;affective,&rdquo; &ldquo;valence,&rdquo; and &ldquo;</span><span class="c5">motivational</span><span class="c7 c5">.&rdquo; Of course all of these terms are somewhat imprecise.</span></p></div><div><p class="c9"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c5">&nbsp;</span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=https://www.nytimes.com/2016/05/16/opinion/consciousness-isnt-a-mystery-its-matter.html&amp;sa=D&amp;source=editors&amp;ust=1648306838885137&amp;usg=AOvVaw3ylKkZPD1If65GKinjLsGG">Attributed</a></span><span class="c7 c5">&nbsp;to Ned Block.</span></p></div><div><p class="c9"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c7 c5">&nbsp;I think insofar as these definitions are substantive, they basically all boil down to some combination of the three listed above.</span></p></div><div><p class="c9"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c5">&nbsp;</span><span class="c5">One might say that consciousness is undiscoverable in this sense, but still a reality. I don&rsquo;t think we have any evidence that this is the case. (If you think you have first-person experience that consciousness is undiscoverable, see my response to &ldquo;That&rsquo;s an interesting argument..&rdquo; below.)</span><span class="c5"><br><br>But in case it is, I should clarify that I&rsquo;m arguing consciousness does not exist (i.e. it&rsquo;s not real), and thus is undiscoverable, rather than arguing for undiscoverability directly.<br><br></span><span class="c5">I also find these distinctions to be fairly semantic. Take an example like a physical feature of the universe that&rsquo;s too large to ever be computed even with the largest supercomputer physically possible. My physics knowledge isn&rsquo;t good enough to know if there&rsquo;s a direct feature, such as the number of atoms in the universe, but we can at least apply arbitrarily large math to make this the case, such as 3^^^^^^3 with however many ^s you need. In this case, the decimal representation seems undiscoverable, but </span><span class="c5">does it exist</span><span class="c5">? Is it real? It seems the definitions of &ldquo;exist&rdquo; and &ldquo;real&rdquo; are unclear in these edge cases, so it&rsquo;s just a matter of semantics.</span><span class="c5">&nbsp;</span><span class="c5">Of course with a very loose definition of &ldquo;real,&rdquo; like something being real if you&rsquo;re able to talk about it (so dragons and other imaginary creatures are real), I would agree that consciousness is real.</span></p></div><div><p class="c9"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c7 c5">&nbsp;As a side note on the evidence in favor of eliminativism, I also think the existence of consciousness in an objective sense would make the world more complicated than a world without it (because you&rsquo;re adding an extra feature to the world), which probably adds the weight of parsimony in favor of eliminativism relative to most non-eliminativist views.</span></p></div><div><p class="c9"><a href="#ftnt_ref8" id="ftnt8">[8]</a><span class="c7 c5">&nbsp;Intelligently in the sense that when you respond, most people will have a pretty good sense of what peaks New York City does or does not have.</span></p></div><div><p class="c9"><a href="#ftnt_ref9" id="ftnt9">[9]</a><span class="c5">&nbsp;I think the imprecision argument also applies to morality. And as with consciousness, the existence of some sort of objective moral reality seems unparsimonious. Moreover, with morality, realism lacks much of the intuitive force that comes with the first-person experience used to argue for consciousness. Thus, I also favor </span><span class="c5 c0">moral eliminativism</span><span class="c5">&nbsp;and </span><span class="c5 c0">moral anti-realism</span><span class="c5">.</span></p></div><div><p class="c9"><a href="#ftnt_ref10" id="ftnt10">[10]</a><span class="c7 c5">&nbsp;I&rsquo;d only be &ldquo;closer&rdquo; and not all the way there because there are other ambiguities besides height, such as whether a mountain needs to be made of earth.</span></p></div><div><p class="c9"><a href="#ftnt_ref11" id="ftnt11">[11]</a><span class="c7 c5">&nbsp;One could argue that even &ldquo;gold&rdquo; is not precise, since there is still in theory imprecision in a term like &ldquo;atom&rdquo; (e.g. What if you saw a gold atom with a new, undiscovered subatomic particle included? Or one in a weird oval shape?). This seems reasonable to me; I agree my discussion assumes precision in some baseline physical properties, and I would take issue with a question like &ldquo;Are these atoms gold?&rdquo; in situations where this imprecision is relevant.</span></p></div><div><p class="c9"><a href="#ftnt_ref12" id="ftnt12">[12]</a><span class="c7 c5">&nbsp;I don&rsquo;t think we should expect the correct views on sentience to lead to better moral outcomes. Indeed, if consciousness were a real, discoverable feature of beings, this might be highly useful in advocating for the welfare of sentient beings.</span></p></div><div><p class="c9"><a href="#ftnt_ref13" id="ftnt13">[13]</a><span class="c5">&nbsp;Here are some precise features I currently think are morally relevant: (1) reinforcement learning, (2) mood-like states, as indicated by behavioral studies suggesting </span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=https://www.cell.com/current-biology/abstract/S0960-9822%252811%252900544-6&amp;sa=D&amp;source=editors&amp;ust=1648306838884547&amp;usg=AOvVaw04A-VP68j_SSar7LKSCMn5">honeybees</a></span><span class="c5">&nbsp;become more pessimistic when agitated, (3) integration of different perception and behavioral domains, which might be at least </span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=https://scholar.harvard.edu/files/jvitti/files/animalconsciousness_cr_0.pdf&amp;sa=D&amp;source=editors&amp;ust=1648306838884727&amp;usg=AOvVaw0kM1wt0c1J63XfMADKtV54">partially lacking</a></span><span class="c5">&nbsp;in honeybees as shown in overshadowing experiments. I wrote more about (1)-(3) in invertebrates in </span><span class="c4 c5"><a class="c12" href="https://www.google.com/url?q=http://jacyreese.com/What_is_it_like_to_be_an_invertebrate.pdf&amp;sa=D&amp;source=editors&amp;ust=1648306838884889&amp;usg=AOvVaw3WZbZNbQho6SEFcSocbsdD">this paper</a></span><span class="c7 c5">&nbsp;I wrote as an undergrad, though my views here are quite tentative.</span></p></div></body></html>