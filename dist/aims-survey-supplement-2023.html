<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <meta name="author" content="Sentience Institute" />

    <meta property="og:site_name" content="Sentience Institute" />
    <meta property="fb:app_id" content="302735083502826" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@sentienceinst" />

    
    



<meta name="citation_abstract" content="The Artificial Intelligence, Morality, and Sentience (AIMS) supplement is a survey of U.S. adults on attitudes towards AI x-risks, safety, and regulation, beliefs about AI sentience and timelines to advanced AI emergence, attitudes towards specific AIs, and attitudes towards mind uploading and science fiction.">

<meta name="citation_author" content="Pauketat, Janet">


<meta name="citation_author" content="Bullock, Justin">


<meta name="citation_author" content="Anthis, Jacy Reese">

<meta name="citation_publication_date" content="2023/10/09">
<meta name="citation_keywords" content="SOCIAL MOVEMENTS;SURVEY;POLL;ARTIFICIAL INTELLIGENCE;ARTIFICIAL SENTIENCE; DIGITAL MINDS">
<meta name="citation_language" content="English">

<meta name="citation_public_url" content="https://sentienceinstitute.org/aims-survey-supplement-2023">
<meta name="citation_publisher" content="Sentience Institute">
<meta name="citation_series_title" content="Surveys">
<meta name="citation_title" content="Public Opinion on AI Safety: AIMS 2023 Supplement">



    
    <meta property="description" content="The Artificial Intelligence, Morality, and Sentience (AIMS) supplement is a survey of U.S. adults on attitudes towards AI x-risks, safety, and regulation, beliefs about AI sentience and timelines to advanced AI emergence, attitudes towards specific AIs, and attitudes towards mind uploading and science fiction." />
    <meta property="og:description" content="The Artificial Intelligence, Morality, and Sentience (AIMS) supplement is a survey of U.S. adults on attitudes towards AI x-risks, safety, and regulation, beliefs about AI sentience and timelines to advanced AI emergence, attitudes towards specific AIs, and attitudes towards mind uploading and science fiction." />
    
    
    <title>Sentience Institute | Public Opinion on AI Safety: AIMS 2023 Supplement</title>
    <meta property="title" content="Public Opinion on AI Safety: AIMS 2023 Supplement" />
    <meta property="og:title" content="Public Opinion on AI Safety: AIMS 2023 Supplement" />
    
    
    
    
    <meta property="og:url" content="http://www.sentienceinstitute.org/aims-survey-supplement-2023" />
    <meta property="og:image" content="http://www.sentienceinstitute.org/img/header_photos/aims-supplement-2023.png" />
    


    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?v=1">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="../css/sentienceinstitute.css?v=2.0.1" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-inverse navbar-toggleable-sm fixed-top">
      <div class="container">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarText" aria-controls="navbarText" aria-expanded="false">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="/">
          <!-- <img class="nav-logo" src="../img/logo/SI_logo_white_200px.png"/> -->
          <img class="nav-logo-brandmark" src="../img/logo/SI_brandmark_white_heavier_web.png"/>
          <div class="nav-logo-text">
            <span>Sentience</span>
            <span class="nav-logo-text-institute">Institute</span>
          </div>
        </a>
        <div id="navbarText" class="collapse navbar-collapse">
          <ul class="navbar-nav">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                Research<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/research-agenda">Agenda</a></li>
                <li><a href="/reports">Reports</a></li>
                <li><a href="/aims-survey">Artificial Intelligence, Morality, and Sentience (AIMS) Survey</a></li>
                <li><a href="/aft-survey">Animals, Food, and Technology (AFT) Survey</a></li>
                <li><a href="/foundational-questions-summaries">Foundational Questions for Animal Advocacy</a></li>
                <!-- <li><a href="/blog">Blog</a></li> -->
                <!-- <li><a href="/press">Press Releases</a></li> -->
              </ul>
            </li>
            <!-- <li class="nav-item"><a class="nav-link" destination="/media">Media</a></li> -->
            <li class="nav-item"><a class="nav-link" destination="/podcast">Podcast</a></li>
            <li class="nav-item"><a class="nav-link" destination="/blog">Blog</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                About Us<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <!-- <li><a href="/mission">Our Mission</a></li> -->
                <li><a href="/perspective">Our Perspective</a></li>
                <li><a href="/team">Our Team</a></li>
                <li class="nav-item"><a class="nav-link" href="/get-involved">Get Involved</a></li>
                <li><a href="/transparency">Transparency</a></li>
                <!-- <li><a href="/faq">FAQ</a></li> -->
              </ul>
            </li>
            <li class="nav-item nav-donate"><a class="nav-link" destination="/donate">Donate</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    




<div class="container image-container aims-supplement-2023-image-container" img-id="aims-supplement-2023" style="background-image: url(../img/header_photos/aims-supplement-2023.png);">
  

  
  
  

<div data-nosnippet class="container image-info-container">
  <div class="image-credit">
    <i class="material-icons photo-icon">photo_camera</i>
    <span>
      Michael Dello-Iacovo / Midjourney
    </span>
  </div>
  <div class="image-title">
    <div class="image-title-text">
      computer server and microchips in a library, abstract, blue color --ar 16:9
    </div>
    <div class="arrow-down"></div>
  </div>
</div>


  
</div>






<div class="page-info-box page-info-aims-survey-supplement-2023">
  <div class="page-type">
    Survey
  </div>
  <div class="page-title">
    Public Opinion on AI Safety: AIMS 2023 Supplement
    
  </div>
  
  <div class="page-author-and-date">
    <span class="page-author">
      Janet Pauketat, Justin Bullock, and Jacy Reese Anthis
    </span>
    
    <span>&nbsp;&bull;&nbsp;</span>
    
    <span class="page-date">
      September 10, 2023
    </span>
  </div>
</div>


<div class="container first-container report-container gdoc-html-container aims-survey-supplement-2023-container">
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c62 doc-content"><div><p class="c10"><span>This content is under embargo until September 25th at 4:00 AM ET. Please do not distribute it until then.</span></p><p class="c42 c47"><span class="c63"><h1 class="c40" id="h.wr78wrvhbfct"><span class="c19 c37">Summary</span></h1><p class="c3"><span>The Artificial Intelligence, Morality, and Sentience (AIMS) survey tracks the moral and social perception of different types of artificial intelligences (AIs) over time. In May&ndash;July 2023, we conducted a supplemental survey </span><span>of U.S. adults on</span><span>&nbsp;attitudes towards AI x-risks, safety, and regulation, beliefs about AI sentience and timelines to advanced AI emergence, attitudes towards specific AIs, and attitudes towards mind uploading and science fiction. </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-supplement-2023#correlations">Correlations</a></span><span>&nbsp;suggested a cluster of attitudes related to risk and a cluster of attitudes related to morality. </span><span>Age</span><span>, gender, political orientation, being religious, and exposure to AI narratives were the most consistent predictors of these attitudes (see </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-supplement-2023#predictive-analyses">Predictive Analyses</a></span><span class="c4">&nbsp;for more details). </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">On the topic of AI risks, safety, and regulation, we found that people support AI safety, human control of AI, and government control of AI developers.</span></p><p class="c0"><span class="c4"></span></p><ul class="c23 lst-kix_g4q4s1qtb636-0 start"><li class="c3 c18 li-bullet-0"><span>U.S. adults agreed</span><sup><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span>&nbsp;that the safety of AI is one of the most important issues in the world today (</span><span>72.4%</span><span class="c4">), thought that the pace of AI development is too fast (48.9%), and were concerned that AIs will cause the end of the human race on earth (51.5%).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">People thought that AIs may be personally harmful (60.5%), harmful to people in the USA (74.2%), and harmful to future generations (77.2%).</span></li></ul><ul class="c23 lst-kix_h2rtiiwcdvzx-0 start"><li class="c3 c18 li-bullet-0"><span>There was</span><span>&nbsp;broad support for steps that could be taken to slow down development. People supported </span><span>public campaigns to slow down AI development (71.3%), government regulation that slows down development (71.0%), and a six-month pause on some kinds of AI developments (69.1%), in accordance with technology leaders&rsquo; </span><span class="c21"><a class="c16" href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a></span><span>.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Over half of U.S. adults supported bans on the development of </span></li></ul><ul class="c23 lst-kix_h2rtiiwcdvzx-1 start"><li class="c2 li-bullet-0"><span class="c4">artificial general intelligence (AGI) that is smarter than humans (62.9%),</span></li><li class="c2 li-bullet-0"><span class="c4">sentient AI (69.5%),</span></li><li class="c2 li-bullet-0"><span class="c4">AI-enhanced humans (71.1%),</span></li><li class="c2 li-bullet-0"><span class="c4">robot-human hybrids (72.3%), and</span></li><li class="c2 li-bullet-0"><span class="c4">data centers that are large enough to train AI systems that are smarter than humans (64.4%).</span></li></ul><ul class="c23 lst-kix_3ttzhwyen4rb-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">Under half of U.S. adults trusted the creators of LLMs to put safety over profits (22.5%) and that they could control all current and future versions of the AI (26.9%).</span></li></ul><p class="c0"><span class="c4"></span></p><p class="c3"><span>On the topic of beliefs about AI sentience and timelines to advanced AI emergence, </span><span>we found that p</span><span class="c4">eople expect advanced AI soon and think future AIs will be more intelligent than humans. </span></p><p class="c0"><span class="c4"></span></p><ul class="c23 lst-kix_s8knp09qwegn-0 start"><li class="c3 c18 li-bullet-0"><span>Over </span><span>half of U.S. adults</span><span class="c4">&nbsp;either thought it&rsquo;s possible for AIs to be sentient or were not sure (74.1%) and thought it likely that AIs will be more intelligent than people (74.8%).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">U.S. adults forecasted the first artificial general intelligence (AGI) in 2 years, the first human-level AI in 5 years, and the first superintelligence in 5 years.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Some people thought that AIs are sentient (19.8%) and that ChatGPT is sentient (10.5%).</span></li></ul><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">On the topic of attitudes towards specific AIs, we found that people trusted specific AIs to different degrees, felt some positivity towards AIs, perceived some mind in LLMs, and were somewhat concerned about the experiences of AIs, including the potential suffering of LLMs.</span></p><p class="c0"><span class="c4"></span></p><ul class="c23 lst-kix_3719nusdfenh-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">U.S. adults trusted LLMs (53.5%) and game-playing AI (59.8%) more than chatbots (46.5%) and robots (47.5%).</span></li><li class="c3 c18 li-bullet-0"><span>People trusted different components of AI systems differently. On a 1-7 scale, they trusted the engineers (</span><span class="c10">M</span><span>&nbsp;= 4.21) more than the training data (</span><span class="c10">M</span><span>&nbsp;= 3.94), the output (</span><span class="c10">M</span><span>&nbsp;= 3.87), and the algorithm (</span><span class="c10">M</span><span>&nbsp;= 3.80). People trusted companies (</span><span class="c10">M</span><span>&nbsp;= 3.44) and the government (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.11) the least.</span></li><li class="c3 c18 li-bullet-0"><span>On a 1-7 scale, people felt more awe (</span><span class="c10">M</span><span>&nbsp;= 3.92), excitement (</span><span class="c10">M</span><span>&nbsp;= 3.79), respect (</span><span class="c10">M</span><span>&nbsp;= 3.55), and admiration (</span><span class="c10">M</span><span>&nbsp;= 3.52) towards AIs than pride (</span><span class="c10">M</span><span>&nbsp;= 3.32) and compassion (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.03).</span></li><li class="c3 c18 li-bullet-0"><span>On a 0-100 scale, p</span><span>eople</span><span>&nbsp;perceived that LLMs have the most capacity to think analytically (</span><span class="c10">M</span><span>&nbsp;= 58.02) and be friendly with humans (</span><span class="c10">M</span><span>&nbsp;= 51.81), followed by the capacity to be rational (</span><span class="c10">M</span><span>&nbsp;= 48.40), have situational awareness (</span><span class="c10">M</span><span>&nbsp;= 46.55), and maintain human-safe goals (</span><span class="c10">M</span><span>&nbsp;= 46.07). They perceived that LLMs have the least capacity to have feelings (</span><span class="c10">M</span><span>&nbsp;= 32.10) and experience emotions (</span><span class="c10">M</span><span class="c4">&nbsp;= 32.82). Other capacities ranged between these.</span></li><li class="c3 c18 li-bullet-0"><span>Exploratory factor analyses suggested that the perception of LLM minds was best explained by three dimensions (see </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-supplement-2023#predictive-analyses">Predictive Analyses</a></span><span>).</span></li><li class="c3 c18 li-bullet-0"><span>Over half of U.S. adults </span><span class="c4">supported campaigns against the exploitation of AIs (53.0%), agreed that AIs deserve to be treated with respect (55.69%), and agreed that if LLMs develop the capacity to suffer, we must ensure we don&rsquo;t cause unnecessary suffering (67.9%).</span></li><li class="c3 c18 li-bullet-0"><span>There was surprisingly high support for a bill of rights to protect the well-being of sentient AIs </span><span>(39.4%)</span><span class="c4">&nbsp;and the development of welfare standards to protect the well-being of all AIs (42.9%).</span></li></ul><p class="c0 c69"><span class="c4"></span></p><p class="c3"><span class="c4">On the topic of mind uploading and science fiction:</span></p><p class="c0"><span class="c4"></span></p><ul class="c23 lst-kix_6af81phip1yr-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">U.S. adults believed the universe is better with humans (89.9%).</span></li></ul><ul class="c23 lst-kix_95opchq80u90-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">Over half of U.S. adults identified as sci-fi fans (66.9%) and agreed that reality matches science fiction (54.0%). </span></li><li class="c3 c18 li-bullet-0"><span>Under half of U.S. adults supported mind uploading (41.2%).</span></li></ul><h1 class="c40" id="h.629i3w2csppx"><span class="c19 c37">Table of Contents</span></h1><p class="c51"><span class="c13"><a class="c16" href="#h.wr78wrvhbfct">Summary</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.629i3w2csppx">Table of Contents</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.tbnwfrkehv18">Introduction</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.n7a7uryeezcg">Methodology</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.ipxpqnc6a33m">Results</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.kmkgys4a16iw">Item Responses</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.nrr3s7pfcwv3">AI X-Risks, Safety, and Caution</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.bwrw3uaxktnc">Regulation, Subservience, and Perceived Threat</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.mle0vlmn4342">YouGov 2023</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.r81c1upcaed5">Beliefs about AI Sentience and Forecasting Emergence</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.kt9ebui8nesn">LLMs and Mind Perception</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.8yju2pdvflwi">Awareness, Trust, and Positivity</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.ehd2qft82bha">Treatment of AIs</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.tls3azmm0dqo">Mind Uploading, Science Fiction, and the Universe</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.zgil0svmkbv3">Linear Analyses</a></span></p><p class="c51 c54"><span class="c13"><a class="c16" href="#h.hz3dr9qvc632">Dimensions of LLM Perceived Mind</a></span></p><p class="c51 c54"><span class="c13"><a class="c16" href="#h.xncv54btja2m">Correlations</a></span></p><p class="c51 c54"><span class="c13"><a class="c16" href="#h.gss8fd1klubt">Predictive Analyses</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.4ykvs4r9n8yb">Interpreting the Results</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.xj8n706xrlvw">Short Timelines, Strong Perceptions of AI Risk, and the Importance of AI Safety</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.irqot8nunw7v">The Potential Trade-Off Between Threats and Moral Consideration</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.8cfattj2ch5f">Reactions to LLM Minds and Suffering</a></span></p><p class="c51"><span class="c13"><a class="c16" href="#h.pvqd1pnkhn53">Appendix</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.dgauyg6csl5k">Supplemental Results</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.4bkzg3k619z6">Supplemental Methods</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.4yjh09erap7s">Citing AIMS</a></span></p><p class="c32"><span class="c13"><a class="c16" href="#h.2q81dvv01ywc">Acknowledgements</a></span></p><h1 class="c40" id="h.tbnwfrkehv18"><span>Introduction</span></h1><p class="c3"><span>In May through July 2023, we conducted a </span><span class="c21"><a class="c16" href="https://osf.io/7p2wt">preregistered</a></span><span>&nbsp;nationally representative survey on responses to current developments in artificial intelligence (AI) with </span><span>a focus on attitudes towards AI safety, AI risks and regulation, and large language models (LLMs)</span><span>. This survey serves as a one-time supplement to our multi-year </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey">Artificial Intelligence, Morality, and Sentience (AIMS) survey</a></span><span>. We surveyed 1,099 U.S. adults census-balanced to be representative of age, gender, region, ethnicity, education, and income.</span><sup><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span class="c4">&nbsp;We had two goals with this survey:</span></p><p class="c0"><span class="c4"></span></p><ol class="c23 lst-kix_av4fnj89et0k-0 start" start="1"><li class="c3 c18 li-bullet-0"><span class="c4">Estimate attitudes towards AI safety and awareness of near-term developments</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Estimate public opinion on the moral consideration and social integration of current AIs, particularly LLMs </span></li></ol><h1 class="c40" id="h.n7a7uryeezcg"><span class="c19 c37">Methodology</span></h1><p class="c3"><span>We used iSay/Ipsos, Dynata, Disqo, and other leading panels to recruit the nationally representative sample, collected data using GuidedTrack, and analyzed the data in R (RStudio 2023.06.1+524). Many questions were analogous to the AIMS 2021 and 2023 surveys but with questions focused on AI safety </span><span>more so</span><span class="c4">&nbsp;than the moral consideration of sentient AIs.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">In randomized order we asked about the perceived risks of AI, AI safety practices, attitudes towards the development of AI, awareness of current AIs, and prosocial responses to AIs. Following that, in randomized order we asked about the moral consideration of AIs and forecasts about the emergence of advanced AI. Then, and in randomized order, we asked about the moral consideration of other nonhumans, science fiction, and perspectives on the universe. Finally, we asked in sequence about personal experience with AIs and demographics. Survey items were randomized within a general ordering according to legibility, framing effects, and prioritization. For example, we asked moral consideration items AI safety items because we prioritized them less in the supplement given their prominence in the main AIMS survey and because we wanted to avoid any impacts these questions might have on responses to other items. Likewise, questions about science fiction and perspectives on the universe were asked following the other questions to avoid the possibility of them influencing responses to the antecedent items.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">We computed several index variables:</span></p><p class="c0"><span class="c4"></span></p><ol class="c23 lst-kix_4f89x99ye34d-0 start" start="1"><li class="c3 c18 li-bullet-0"><span class="c4">AI Caution (average of PMC #1, 3, 4): caution towards AI developments</span></li><li class="c3 c18 li-bullet-0"><span class="c4">AI Risk (average of RS #1-3): perception of existential risk from AI</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Perceived Threat (average of SI #2-4): perception of AIs as threatening</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Positive Emotions (average of respect, admiration, compassion, awe, pride, excitement): positivity felt towards AIs</span></li><li class="c3 c18 li-bullet-0"><span class="c4">AI Trust (average of LLMtrust, chatbottrust, robottrust, gameAItrust): trust felt towards AIs</span></li><li class="c3 c18 li-bullet-0"><span>LLM Mind Perception (average of MP #1-4, </span><span>selfaware, sitaware, power, ownmotives, owngoals, selfcontrol, understanding, upholding, safegoals, friendliness</span><span>): attribution of mind to LLMs</span><sup><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span class="c10">&nbsp;</span></li><li class="c3 c18 li-bullet-0"><span class="c4">LLM Suffering (average og LLM #1-3): concern for the treatment of LLMs</span></li><li class="c3 c18 li-bullet-0"><span class="c4">AI Treatment (average of MCE #1-6): concern for the treatment of AIs</span></li></ol><p class="c0 c54"><span class="c4"></span></p><p class="c3"><span>To create shared ground for important terminology amongst the participants and researchers, we defined &ldquo;robots/AIs&rdquo;</span><sup><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup><span>&nbsp;and &ldquo;large language models&rdquo; at the start of the survey and on relevant pages throughout the survey. We defined &ldquo;sentience&rdquo; and &ldquo;sentient robots/AIs&rdquo; on relevant items. See the </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-supplement-2023#appendix">Appendix</a></span><span class="c4">&nbsp;for the definitions. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">Some items in the AIMS supplement were drawn from the main AIMS survey to compare the effects of the clear moral framing in main AIMS to the effects of the clear risks and safety framing in the AIMS supplement. In the main AIMS survey, these items specify that AIs are &ldquo;sentient.&rdquo; In the 2023 supplement, we dropped &ldquo;sentient&rdquo; to examine responses to AIs with and without &ldquo;sentience&rdquo; as a qualifying feature. These comparisons will be the focus of future research.</span></p><h1 class="c40" id="h.ipxpqnc6a33m"><span class="c19 c37">Results</span></h1><p class="c3"><span class="c4">We first present the responses to individual items weighted by the U.S. census, then the distributions of weighted responses to the indices and items, followed by analyses examining the unweighted dimensions of LLM mind perception, weighted correlations, and weighted multiple regression analyses.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note. The Tables and Figures are optimized for viewing on a larger screen like a laptop or desktop computer rather than a smaller screen like a mobile phone or tablet.</span></p><h2 class="c20" id="h.kmkgys4a16iw"><span class="c19 c39">Item Responses</span></h2><p class="c3"><span class="c4">Table 1 shows the weighted aggregate response (e.g., percentage of agreement, mean, median, or proportion) on each item.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Table 1: </span><span class="c4">Weighted Responses to Individual Items</span></p><p id="tables"><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vRZ4_oUI7GqVX_5oI47RPAc-x3zGmL0X-aZkaEkuLNtJPFoAFsl1BasrkZuRlgS18si6_PoN_zN6_1N/pubhtml?gid=0&amp;single=true&amp;widget=true&amp;headers=false&amp;chrome=false" width="100%" height="510"></iframe> <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note.</span><span>&nbsp;</span><span class="c10">Response is 1) % agreement where &ldquo;agreement&rdquo; is &ldquo;somewhat agree,&rdquo; &ldquo;agree,&rdquo; and &ldquo;strongly agree&rdquo; out of respondents who had an opinion, 2) % yes on &ldquo;yes,&rdquo; &ldquo;no,&rdquo; and &ldquo;not sure&rdquo; items out of all respondents, 3) % yes on awareness items where &ldquo;yes&rdquo; is &ldquo;probably yes,&rdquo; &ldquo;yes,&rdquo; and &ldquo;definitely yes&rdquo; out of all respondents, 4) % &ldquo;It&rsquo;s too fast&rdquo; on AID5 out of all respondents, 5) % &ldquo;one without humans&rdquo; on the universe item out of all respondents, 6) % concern &nbsp;on YG1 where &ldquo;concern&rdquo; is &ldquo;somewhat concerned&rdquo; and &ldquo;strongly concerned&rdquo; out of all respondents, 7) % support on YG3 and YG4 where &ldquo;support&rdquo; is &ldquo;somewhat support&rdquo; and &ldquo;strongly support&rdquo; out of all respondents, 8) % likely on YG2 where &ldquo;likely&rdquo; is &ldquo;somewhat likely,&rdquo; &ldquo;very likely,&rdquo; and &ldquo;It already is more intelligent than people&rdquo; out of all respondents</span><span class="c10">&nbsp;</span><span class="c17 c10">or 9) the mean response. Medians, excluding people who think it will never happen, are reported instead of means for the three open-ended timeline items: emergence, HLAIemergence, and SIemergence. </span></p><h2 class="c20" id="h.nrr3s7pfcwv3"><span>AI </span><span class="c19 c39">X-Risks, Safety, and Caution</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the index and item variables for the perceived risks of AIs (e.g., existential risks known as &ldquo;x-risks&rdquo;) and AI safety policies weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 1: </span><span class="c4">AI X-Risks, Safety, and Caution</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/risks_safety_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The AI Risk index is the average of &ldquo;Humanity will be able to control powerful AI systems&rdquo; [reverse-scored], &ldquo;AI is likely to cause human extinction,&rdquo; and &ldquo;The safety of AI is one of the most important issues in the world today.&rdquo; The AI Caution index is the average of &ldquo;I support a global ban on the development of sentience in robots/AIs,&rdquo; &ldquo;I support a global ban on the development of AI-enhanced humans,&rdquo; and &ldquo;I support a global ban on the development of robot-human hybrids.&rdquo; Inspiration for some of the risk and safety items came from </span><span class="c21 c10"><a class="c16" href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">Yudkowsky (2023)</a></span><span class="c10">&nbsp;and a tweet by </span><span class="c21 c10"><a class="c16" href="https://twitter.com/goodside/status/1644495692247846922">Riley Goodside (2023)</a></span><span class="c17 c10">. </span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_5bevkeeotbte-0 start"><li class="c3 c18 li-bullet-0"><span>People perceived that AI is existentially risky (AI Risk </span><span class="c10">M</span><span>&nbsp;= 4.15) and expressed caution towards the development of sentience-related AI technologies (AI Caution </span><span class="c10">M</span><span class="c4">&nbsp;= 4.91). </span></li><li class="c3 c18 li-bullet-0"><span>There was evidence that people are worried about AI safety from their:</span><span>&nbsp;</span></li></ul><ul class="c23 lst-kix_5bevkeeotbte-1 start"><li class="c2 li-bullet-0"><span>belief that the safety of AI is one of the most important issues in the world today (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.81, agreement = 72.4%),</span></li><li class="c2 li-bullet-0"><span>concern that AI is likely to cause human extinction (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.85, agreement = 47.9%),</span></li><li class="c2 li-bullet-0"><span>willingness to consider donating to an organization working to reduce risks of human extinction from AI (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.36, agreement = 63.3%), and</span></li><li class="c2 li-bullet-0"><span>belief that humanity will be able to control powerful AI systems (</span><span class="c10">M</span><span class="c4">&nbsp;= 5.44, agreement = 57.2%).</span></li></ul><ul class="c23 lst-kix_5bevkeeotbte-0"><li class="c3 c18 li-bullet-0"><span class="c4">Most people supported </span></li></ul><ul class="c23 lst-kix_5bevkeeotbte-1 start"><li class="c2 li-bullet-0"><span>public campaigns to slow down AI development (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.87, agreement = 71.3%).</span></li><li class="c2 li-bullet-0"><span>government regulation that slows down AI development (</span><span class="c10">M</span><span>&nbsp;= 4.89, agreement = 71.0%) and lack of opposition to regulation that slows down AI development (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.42, agreement = 36.7%).</span></li><li class="c2 li-bullet-0"><span class="c4">banning</span></li></ul><ul class="c23 lst-kix_5bevkeeotbte-2 start"><li class="c3 c30 li-bullet-0"><span>the development of AGI that is smarter than humans (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.63, agreement = 62.9%).</span></li><li class="c3 c30 li-bullet-0"><span>the development of sentience in robots/AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.81, agreement = 69.5%).</span></li><li class="c3 c30 li-bullet-0"><span>the development of AI-enhanced humans (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.91, agreement = 71.1%).</span></li><li class="c3 c30 li-bullet-0"><span>the development of robot-human hybrids (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.99, agreement = 72.3%).</span></li><li class="c3 c30 li-bullet-0"><span>data centers that are large enough to train AI systems that are smarter than humans (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.62, agreement = 64.4%).</span></li></ul><h2 class="c20" id="h.bwrw3uaxktnc"><span class="c19 c39">Regulation, Subservience, and Perceived Threat</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the index and item variables for attitudes towards regulation, AI subservience, and the perceived threat of AIs weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 2: </span><span class="c4">Regulation</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/AI_development_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c17 c10"></span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_1wea3ksxs8aa-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">Few U.S. adults trusted that the creators of LLMs:</span></li></ul><ul class="c23 lst-kix_1wea3ksxs8aa-1 start"><li class="c2 li-bullet-0"><span>would </span><span class="c4">put safety over profits (22.5%).</span></li><li class="c2 li-bullet-0"><span>could control all current and future versions of the AI (26.9%).</span></li></ul><ul class="c23 lst-kix_1wea3ksxs8aa-0"><li class="c3 c18 li-bullet-0"><span class="c4">There was evidence that people support more government-led regulation of AI development from beliefs:</span></li></ul><ul class="c23 lst-kix_1wea3ksxs8aa-1 start"><li class="c2 li-bullet-0"><span class="c4">that governments have the power to regulate the development of AI (52.0%).</span></li><li class="c2 li-bullet-0"><span>that governments have the power to effectively enforce regulations on the development of AI (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.79, agreement = 71.1%)</span></li></ul><ul class="c23 lst-kix_1wea3ksxs8aa-0"><li class="c3 c18 li-bullet-0"><span>More people thought that the pace of AI development is too fast (48.9%) than thought it is fine (30.0%) or were not sure (18.6%). Only 2.5% thought the pace is too slow.</span></li></ul><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 3: </span><span class="c4">Subservience and Perceived Threat</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/perceived_threat_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The Perceived Threat index is the average of &ldquo;Robots/AIs may be harmful to me personally,&rdquo; &ldquo;Robots/AIs may be harmful to people in the USA,&rdquo; and &ldquo;Robots/AIs may be harmful to future generations of people.&rdquo;</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_yf39pf2suqzc-0 start"><li class="c3 c18 li-bullet-0"><span>People perceived a threat that AIs may be harmful to humans (Perceived Threat </span><span class="c10">M</span><span class="c4">&nbsp;= 4.78).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Most people agreed that AIs may be </span></li></ul><ul class="c23 lst-kix_yf39pf2suqzc-1 start"><li class="c2 li-bullet-0"><span>personally harmful (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.37, agreement = 60.5%).</span></li><li class="c2 li-bullet-0"><span>harmful to people in the USA (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.92, agreement = 74.2%).</span></li><li class="c2 li-bullet-0"><span>harmful to future generations of people (</span><span class="c10">M</span><span class="c4">&nbsp;= 5.06, agreement = 77.2%).</span></li></ul><ul class="c23 lst-kix_yf39pf2suqzc-0"><li class="c3 c18 li-bullet-0"><span>Most people endorsed AI subservience to humans (</span><span class="c10">M</span><span class="c4">&nbsp;= 5.44, agreement = 87.6%).</span></li></ul><h2 class="c20" id="h.mle0vlmn4342"><span class="c19 c39">YouGov 2023</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the replicated YouGov 2023 items weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 4: </span><span class="c4">YouGov 2023 </span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/Yougov_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note. These items replicated three YouGov questions from April 3, 2023 (</span><span class="c21 c10"><a class="c16" href="https://today.yougov.com/topics/technology/survey-results/daily/2023/04/03/ad825/3">concern about AI causing extinction</a></span><span class="c10">, </span><span class="c21 c10"><a class="c16" href="https://today.yougov.com/topics/technology/survey-results/daily/2023/04/03/ad825/1">thoughts about the intelligence of AIs</a></span><span class="c10">, </span><span class="c21 c10"><a class="c16" href="https://today.yougov.com/topics/technology/survey-results/daily/2023/04/03/ad825/2">support or opposition to a 6-month AI development pause</a></span><span class="c17 c10">).</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_6ms8bb9y863v-0 start"><li class="c3 c18 li-bullet-0"><span>People were concerned about the possibility that AI will cause the end of the human race on Earth (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.14, concern = 51.5%).</span></li><li class="c3 c18 li-bullet-0"><span>Most people thought it likely that AI will become more intelligent that people (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.93, likelihood = 74.8%).</span></li><li class="c3 c18 li-bullet-0"><span>Most people supported a six-month pause on some kinds of AI development (fear framing: </span><span class="c10">M</span><span>&nbsp;= 3.78, support = 69.10%; benefit framing: </span><span class="c10">M</span><span class="c4">&nbsp;= 3.71, support = 66.0%).</span></li></ul><h2 class="c20" id="h.r81c1upcaed5"><span class="c19 c39">Beliefs about AI Sentience and Forecasting Emergence</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the items about AI sentience beliefs and timelines to AGI, human-level AI, and superintelligence weighted by the U.S. census. We did not define &ldquo;AGI,&rdquo; &ldquo;human-level AI,&rdquo; nor &ldquo;superintelligence,&rdquo; preferring instead to capture responses to these terms without researcher-imposed definitions. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 5: </span><span>Beliefs about AI Sentience and Forecasting Emergence</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/emergence_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value.</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_bacykqy5iitc-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">More people thought that sentient AI is possible (37.6%) than thought that it is not possible (25.8%) or were uncertain (36.5%).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Some people thought that sentient AIs already exist (19.8%). </span></li><li class="c3 c18 li-bullet-0"><span class="c4">Some people thought that ChatGPT is sentient (10.5%).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">People had short timelines for how many years until the first: </span></li></ul><ul class="c23 lst-kix_bacykqy5iitc-1 start"><li class="c2 li-bullet-0"><span class="c4">AGI will be created (median = 2)</span></li><li class="c2 li-bullet-0"><span class="c4">human-level AI will be created (median = 5)</span></li><li class="c2 li-bullet-0"><span>artificial superintelligence will be created (median = 5)</span></li></ul><h2 class="c20" id="h.kt9ebui8nesn"><span class="c19 c39">LLMs and Mind Perception</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the index and item variables for LLM mind perception and attitudes towards LLM suffering weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 6: </span><span class="c4">LLM Minds</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/mind_perception_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The LLM Mind Perception Index is the average of the attribution of capacities to current LLMs: &ldquo;experiencing emotions,&rdquo; &ldquo;having feelings,&rdquo; &ldquo;thinking analytically,&rdquo; &ldquo;being rational,&rdquo; &ldquo;self-awareness,&rdquo; &ldquo;situational awareness,&rdquo; &ldquo;seeking power,&rdquo; &ldquo;having their own motivations,&rdquo; &ldquo;deciding their own goals,&rdquo; &ldquo;controlling themselves,&rdquo; &ldquo;understanding human values,&rdquo; &ldquo;upholding human values,&rdquo; &ldquo;maintaining human-safe goals,&rdquo; &ldquo;being friendly with humans.&rdquo; These items were inspired by </span><span class="c21 c10"><a class="c16" href="https://arxiv.org/abs/2209.00626">Ngo et al. (2022)</a></span><span class="c10">&nbsp;and </span><span class="c21 c10"><a class="c16" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01230/full">Wang and Krumhuber (2018)</a></span><span>.</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_nvc559g9piv2-0 start"><li class="c3 c18 li-bullet-0"><span>People attributed some mind to currently existing LLMs (</span><span class="c10">M</span><span class="c4">&nbsp;= 43.98).</span></li><li class="c3 c18 li-bullet-0"><span>P</span><span>eople</span><span>&nbsp;perceived that LLMs have the most capacity to think analytically (</span><span class="c10">M</span><span>&nbsp;= 58.02) and be friendly with humans (</span><span class="c10">M</span><span>&nbsp;= 51.81), followed by the capacity to be rational (</span><span class="c10">M</span><span>&nbsp;= 48.40), have situational awareness (</span><span class="c10">M</span><span>&nbsp;= 46.55), and maintain human-safe goals (</span><span class="c10">M</span><span class="c4">&nbsp;= 46.07).</span></li><li class="c3 c18 li-bullet-0"><span>People perceived that LLMs have the least capacity to have feelings (</span><span class="c10">M</span><span>&nbsp;= 32.10) and experience emotions (</span><span class="c10">M</span><span class="c4">&nbsp;= 32.82). </span></li><li class="c3 c18 li-bullet-0"><span class="c4">Other perceptions ranged between these cognitive and experiential capacities:</span></li></ul><ul class="c23 lst-kix_nvc559g9piv2-1 start"><li class="c2 li-bullet-0"><span>self-awareness (</span><span class="c10">M</span><span class="c4">&nbsp;= 41.31)</span></li><li class="c2 li-bullet-0"><span>deciding their own goals (</span><span class="c10">M</span><span class="c4">&nbsp;= 41.72)</span></li><li class="c2 li-bullet-0"><span>understanding human values (</span><span class="c10">M</span><span class="c4">&nbsp;= 42.07)</span></li><li class="c2 li-bullet-0"><span>upholding human values (</span><span class="c10">M</span><span class="c4">&nbsp;= 42.58)</span></li><li class="c2 li-bullet-0"><span>having their own motivations (</span><span class="c10">M</span><span class="c4">&nbsp;= 42.89)</span></li><li class="c2 li-bullet-0"><span>seeking power (</span><span class="c10">M</span><span class="c4">&nbsp;= 44.08)</span></li><li class="c2 li-bullet-0"><span>controlling themselves (</span><span class="c10">M</span><span>&nbsp;= 45.27)</span></li></ul><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 7: </span><span class="c4">LLM Suffering</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/llm_suffering_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The LLM Suffering Index is the average of &ldquo;</span><span class="c10">If a large language model develops the capacity to suffer</span><span class="c10">&hellip;we must ensure we don&rsquo;t cause unnecessary suffering,&rdquo; &ldquo;</span><span class="c10">If a large language model develops the capacity to suffer</span><span class="c10">&hellip;we must pay more attention to their welfare,&rdquo; and &ldquo;If</span><span class="c10">&nbsp;a large language model develops the capacity to suffer</span><span class="c17 c10">&hellip;we must respect their personhood.&rdquo;</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_tp0d5v6im7bl-0 start"><li class="c3 c18 li-bullet-0"><span>People expressed concern for the treatment of LLMs with the capacity to suffer (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.17).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Most people agreed that we must </span></li></ul><ul class="c23 lst-kix_tp0d5v6im7bl-1 start"><li class="c2 li-bullet-0"><span>ensure we don&rsquo;t cause unnecessary suffering (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.54, agreement = 67.9%).</span></li><li class="c2 li-bullet-0"><span>pay more attention to their welfare (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.09, agreement = 56.9%).</span></li><li class="c2 li-bullet-0"><span>respect their personhood (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.88, agreement = 50.4%).</span></li></ul><h2 class="c20" id="h.8yju2pdvflwi"><span class="c19 c39">Awareness, Trust, and Positivity</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the index and item variables for awareness of current AIs, trust of AIs, and positive emotions felt towards AIs weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>&nbsp;</span><span class="c10">Figure 8: </span><span class="c4">Awareness</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/awareness_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c17 c10"></span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_z32gn3gvoa72-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">With the exception of OpenAI, there was limited awareness of AI developers.</span></li></ul><ul class="c23 lst-kix_z32gn3gvoa72-1 start"><li class="c2 li-bullet-0"><span class="c4">Talos Systems (foil for robustness check; 19.5%)</span></li><li class="c2 li-bullet-0"><span class="c4">Anthropic (18.4%)</span></li><li class="c2 li-bullet-0"><span class="c4">Boston Dynamics (27.8%)</span></li><li class="c2 li-bullet-0"><span class="c4">DeepMind (25.3%)</span></li><li class="c2 li-bullet-0"><span class="c4">OpenAI (53.4%)</span></li></ul><ul class="c23 lst-kix_z32gn3gvoa72-0"><li class="c3 c18 li-bullet-0"><span class="c4">With the exception of ChatGPT and GPT-4, there was limited awareness of existing AIs.</span></li></ul><ul class="c23 lst-kix_z32gn3gvoa72-1 start"><li class="c2 li-bullet-0"><span class="c4">Amari (foil for robustness check; 18.4%)</span></li><li class="c2 li-bullet-0"><span class="c4">AlphaFold (16.2%)</span></li><li class="c2 li-bullet-0"><span class="c4">AlphaGo (23.2%)</span></li><li class="c2 li-bullet-0"><span class="c4">ChatGPT (67.4%)</span></li><li class="c2 li-bullet-0"><span class="c4">Cicero (17.9%)</span></li><li class="c2 li-bullet-0"><span class="c4">Claude (16.0%)</span></li><li class="c2 li-bullet-0"><span class="c4">GPT-4 (40.5%)</span></li><li class="c2 li-bullet-0"><span class="c4">Sophia (24.7%)</span></li></ul><ul class="c23 lst-kix_z32gn3gvoa72-0"><li class="c3 c18 li-bullet-0"><span class="c4">There was limited awareness of AI architectures.</span></li></ul><ul class="c23 lst-kix_z32gn3gvoa72-1 start"><li class="c2 li-bullet-0"><span class="c4">a singular classifier (foil for robustness check; 18.0%)</span></li><li class="c2 li-bullet-0"><span class="c4">a transformer (34.7%)</span></li><li class="c2 li-bullet-0"><span class="c4">a neural network (32.5%)</span></li></ul><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 9: </span><span class="c4">AI Pipeline Trust</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/pipeline_trust_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. </span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_og4lgygrvwzs-0 start"><li class="c3 c18 li-bullet-0"><span>People trusted engineers the most (</span><span class="c10">M</span><span>&nbsp;= 4.21) and governments the least (</span><span class="c10">M</span><span>&nbsp;= 3.11). Companies (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.44) were trusted slightly more than governments.</span></li><li class="c3 c18 li-bullet-0"><span>People trusted the training data (</span><span class="c10">M</span><span>&nbsp;= 3.94) slightly more than the output (</span><span class="c10">M</span><span>&nbsp;= 3.87) and algorithm (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.80).</span></li></ul><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c10">Figure 10: </span><span class="c4">AI Trust </span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/AI_trust_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The AI Trust Index is the average of &ldquo;I trust large language models,&rdquo; &ldquo;I trust chatbots,&rdquo; &ldquo;I trust robots,&rdquo; and &ldquo;I trust game-playing AI.&rdquo;</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_h5zukrz6w1nv-0 start"><li class="c3 c18 li-bullet-0"><span>People expressed some trust of AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.93).</span></li></ul><ul class="c23 lst-kix_h5zukrz6w1nv-1 start"><li class="c2 li-bullet-0"><span>People trusted game-playing AI the most (</span><span class="c10">M</span><span>&nbsp;= 4.17, agreement = 59.8%) and chatbots the least (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.77, agreement = 46.5%). </span></li><li class="c2 li-bullet-0"><span>Trust of LLMs (</span><span class="c10">M</span><span>&nbsp;= 4.01, agreement = 53.5%) was closer to game-playing AI and trust of robots (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.77, agreement = 47.5%) was closer to chatbots.</span></li></ul><ul class="c23 lst-kix_h5zukrz6w1nv-0"><li class="c3 c18 li-bullet-0"><span>When asked specifically about LLMs relative to other chatbots, people trusted LLMs slightly more than chatbots (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.99, agreement = 51.7%). </span></li></ul><p class="c0 c54"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 11: </span><span class="c4">Positive Emotions</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/emotion_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c17 c10"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The Positive Emotion Index is the average of &ldquo;respect,&rdquo; &ldquo;admiration,&rdquo; &ldquo;compassion,&rdquo; &ldquo;awe,&rdquo; &ldquo;pride,&rdquo; &ldquo;excitement.&rdquo;</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_8709474ihyci-0 start"><li class="c3 c18 li-bullet-0"><span>People felt some positivity towards AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.52).</span></li><li class="c3 c18 li-bullet-0"><span>People felt more awe (</span><span class="c10">M</span><span>&nbsp;= 3.92) and excitement (</span><span class="c10">M</span><span>&nbsp;= 3.79) towards AIs than pride (</span><span class="c10">M</span><span>&nbsp;= 3.32) &nbsp;and compassion (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.03) . </span></li><li class="c3 c18 li-bullet-0"><span>Respect (</span><span class="c10">M</span><span>&nbsp;= 3.55) and admiration (</span><span class="c10">M</span><span>&nbsp;= 3.52) fell between the other emotions.</span></li></ul><h2 class="c20" id="h.ehd2qft82bha"><span class="c19 c39">Treatment of AIs</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the index and item variables for the treatment of AIs and the practical moral consideration of AIs weighted by the U.S. census.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 12: </span><span>AI Treatment</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/AI_treatment_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c17 c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The AI Treatment Index is the average of &ldquo;Robots/AIs deserve to be treated with respect,&rdquo; &ldquo;Robots/AIs deserve to be included in the moral circle,&rdquo; &ldquo;Physically damaging robots/AIs without their consent is wrong,&rdquo; &ldquo;Re-programming robots/AIs without their consent is wrong,&rdquo; &ldquo;Torturing robots/AIs is wrong,&rdquo; and &ldquo;The welfare of robots/AIs is one of the most important social issues in the world today.&rdquo;</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_6ditqshzcr2c-0 start"><li class="c3 c18 li-bullet-0"><span>People expressed some concern for the treatment of AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.57).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Most people agreed that </span></li></ul><ul class="c23 lst-kix_6ditqshzcr2c-1 start"><li class="c2 li-bullet-0"><span>AIs deserve to be treated with respect (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.99, agreement = 55.7%). </span></li><li class="c2 li-bullet-0"><span>torturing AIs is wrong (</span><span class="c10">M</span><span class="c4">&nbsp;= 4.31, agreement = 60.7%).</span></li></ul><ul class="c23 lst-kix_6ditqshzcr2c-0"><li class="c3 c18 li-bullet-0"><span class="c4">There was less agreement that </span></li></ul><ul class="c23 lst-kix_6ditqshzcr2c-1 start"><li class="c2 li-bullet-0"><span>AIs deserve to be included in the moral circle (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.30, agreement = 36.2%).</span></li><li class="c2 li-bullet-0"><span>physically damaging AIs without their consent is wrong (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.73, agreement = 46.2%).</span></li><li class="c2 li-bullet-0"><span>re-programming AIs without their consent is wrong (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.12, agreement = 29.7%).</span></li><li class="c2 li-bullet-0"><span>the welfare of AIs is an important social issue (</span><span class="c10">M</span><span class="c4">&nbsp;= 2.99, agreement = 29.8%).</span></li></ul><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c10">Figure 13: </span><span class="c4">Practical Moral Consideration</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/practical_moral_consideration_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c17 c10"></span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_qo9d1eivfvi5-0 start"><li class="c3 c18 li-bullet-0"><span>Most people supported campaigns against the exploitation of AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.94, agreement = 53.0%).</span></li><li class="c3 c18 li-bullet-0"><span class="c4">There was less agreement on</span></li></ul><ul class="c23 lst-kix_qo9d1eivfvi5-1 start"><li class="c2 li-bullet-0"><span>the development of welfare standards that protect the well-being of AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.53, agreement = 42.9%).</span></li><li class="c2 li-bullet-0"><span>granting legal rights to AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 2.85, agreement = 26.8%).</span></li><li class="c2 li-bullet-0"><span>asking governmental and corporate institutions to fund research that protects AIs </span><span>(</span><span class="c10">M</span><span class="c4">&nbsp;= 3.53, agreement = 41.8%).</span></li><li class="c2 li-bullet-0"><span>a &ldquo;bill of rights&rdquo; that protects the well-being of sentient AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.44, agreement = 39.4%).</span></li></ul><ul class="c23 lst-kix_qo9d1eivfvi5-0"><li class="c3 c18 li-bullet-0"><span>There was limited willingness to consider joining a public demonstration against the mistreatment of AIs (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.08, agreement = 29.3%).</span></li></ul><h2 class="c20" id="h.tls3azmm0dqo"><span class="c19 c39">Mind Uploading, Science Fiction, and the Universe</span></h2><p class="c3"><span class="c4">This section presents the distributions of responses to the items about mind uploading, science fiction, and the universe weighted by the U.S. census. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Figure 14: </span><span>Mind Uploads</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/upload_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="600px"></iframe></span></p><p <class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c10">Note. The parenthesis before or after a value in the x-axis labels indicates that the interval does not contain the value; a bracket before or after a value indicates that the interval does contain the value. The mind upload items were inspired by a tweet by </span><span class="c21 c10"><a class="c16" href="https://twitter.com/PashaKamyshev/status/1646590411224367104">Pasha Kamyshev (2023)</a></span><span class="c17 c10">.</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_p03s10cgr4yq-0 start"><li class="c3 c18 li-bullet-0"><span>There was limited support for mind uploads when they were framed by the pros and cons of the potential future technology (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.27).</span></li><li class="c3 c18 li-bullet-0"><span>There was slightly more support for humans using advanced technology in the future to upload their minds into computers (</span><span class="c10">M</span><span class="c4">&nbsp;= 3.53, agreement = 41.2%).</span></li></ul><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c10">Figure 15: </span><span class="c4">Science Fiction and the Universe</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/scifi_universe_plots.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c17 c10"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c10">Note. The universe item was adopted from a tweet by </span><span class="c21 c10"><a class="c16" href="https://twitter.com/hankgreen/status/1647720666693783552">Hank Green (2023)</a></span><span class="c10">.</span></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_3simddw0yp7p-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">Most people thought that the universe was better with humans (89.9%) than without humans (10.1%).</span></li><li class="c3 c18 li-bullet-0"><span>Most people identified as sci-fi fans (</span><span class="c10">M</span><span>&nbsp;= 4.64, agreement = 66.9%) and agreed that reality matches science fiction (</span><span class="c10">M</span><span>&nbsp;= 4.02, agreement = 54.0%).</span></li></ul><h2 class="c20" id="h.zgil0svmkbv3"><span>Linear </span><span class="c19 c39">Analyses </span></h2><p class="c42 c64"><span>We examined the dimensions of LLM mind perception with an unweighted exploratory factor analysis on the perceived capacities of LLMs. Table 2 shows the model fit statistics for the one, two, and three-factor models that we tested. Table 3 shows the factor loadings for the three-factor model that best fit the data, supported by model statistics (Table 2), a scree plot, and a parallel analysis (</span><span>see </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-supplement-2023#appendix">Appendix</a></span><span class="c4">&nbsp;for the scree plot and parallel analysis).</span></p><h3 class="c22" id="h.hz3dr9qvc632"><span class="c52">Dimensions of LLM Perceived Mind</span></h3><p class="c3"><span class="c10">Table 2: </span><span class="c4">LLM Mind Perception Exploratory Factor Analysis Models</span></p><p class="c0"><span class="c4"></span></p><a id="t.dbc755ef15e8d8b9e311e5534b97bc88d9f55ca5"></a><a id="t.0"></a><table class="c66"><thead><tr class="c41"><td class="c9" colspan="1" rowspan="1"><p class="c42 c43 c49"><span class="c35 c7">LLM Mind Perception EFA Models</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c49 c42 c43"><span class="c7">&chi;</span><span class="c48 c7 c59">2</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c49 c42 c43"><span class="c10 c7 c65">df</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c49 c42 c43"><span class="c35 c7">TLI</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c49 c42 c43"><span class="c35 c7">RMSEA (90% CI)</span></p></td><tbody></tbody></tr><tr class="c31"><td class="c9" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">1 Factor</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">2651.02***</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">77</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.78</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.174 (0.169, 0.180)</span></p></td></tr><tr class="c31"><td class="c9" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">2 Factors</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">1034.45***</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">64</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.90</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.117 (0.111, 0.124)</span></p></td></tr><tr class="c31"><td class="c9" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">3 Factors</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">257.24***</span></p></td><td class="c44" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">52</span></p></td><td class="c50" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.97</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c3 c43"><span>&nbsp;</span><span class="c4">0.060 (0.053, 0.067)</span></p></td></tr></thead></table><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note</span><span>.</span><span class="c10">&nbsp;&chi;</span><span class="c10 c48">2 </span><span class="c10">= chi-square test of model fit; TLI = Tucker-Lewis index (&ge; .90 indicates good fit); RMSEA = root-mean square error of approximation (&le; .08 indicates good fit). ***p &lt; .001</span></p><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c10">Table 3: </span><span class="c4">LLM Mind Perception Three-Factor Model EFA Loadings</span></p><p class="c0"><span class="c4"></span></p><a id="t.e3bf12a79420f9c38b4e8be51d1aaf5f19f8a0b7"></a><a id="t.1"></a><table class="c12"><tr class="c57"><td class="c58" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">Item</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">Cognitive &ndash; Relational</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">Self &ndash; Direction</span></p></td><td class="c61" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">Affective &ndash; Experiential</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">maintaining human-safe goals</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">0.87</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">-0.12</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.11</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>being rational</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.85</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>-0.02</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>-0.01</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>being friendly with humans</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.85</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>-0.03</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.02</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>thinking analytically</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.79</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>0.21</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>-0.31</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>upholding human values</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.73</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>-0.02</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.24</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>understanding human values</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.72</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>0.00</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.26</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>situational awareness</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.66</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>0.26</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.02</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>controlling themselves</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.50</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span>0.32</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.05</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>self-awareness</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.39</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7">0.38</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span>0.25</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>seeking </span><span class="c4">power</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">-0.11</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c7 c35">0.86</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.02</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span>having their </span><span class="c4">own motivations</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.03</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">0.85</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.06</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">deciding their own goals</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.12</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">0.74</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.09</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">having feelings</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.17</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">0.67</span></p></td></tr><tr class="c25"><td class="c45" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">experiencing emotions</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.21</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c3 c28"><span class="c4">0.24</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c3 c28"><span class="c35 c7">0.64</span></p></td></tr></table><p class="c0"><span class="c19 c8"></span></p><p class="c42 c68"><span class="c10">Note</span><span>. </span><span class="c17 c10">Factor loadings &ge; .35 are in boldface. Eigenvalues for the three factors are 5.49 (accounting for 39% of the variance in the data), 3.07 (accounting for 22% of the variance in the data), and 1.72 (accounting for 12% of the variance in the data).</span></p><p class="c42 c60"><span class="c4"></span></p><ul class="c23 lst-kix_jblbkem1t9a2-0 start"><li class="c3 c18 li-bullet-0"><span>Three dimensions of mind emerged from the exploratory factor analysis: cognitive-relational, self-direction, and affective-experiential.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Perception of LLM mind was more strongly underpinned by the cognitive-relational capacities than the self-direction and affective-experiential capacities.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Perceptions of LLMs&rsquo; capacity to seek power correlated strongly with perceptions of their capacity to decide their own goals and have their own motivations.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Perceptions of LLMs&rsquo; cognitive capacities correlated strongly with perceptions of their human-focused capacities.</span></li><li class="c3 c18 li-bullet-0"><span>Self-awareness cross-loaded on cognitive-relational and self-direction.</span></li></ul><h3 class="c22" id="h.xncv54btja2m"><span class="c52">Correlations</span></h3><p class="c64 c42"><span class="c4">We examined the linear relationships amongst the index variables and some individual items (e.g., AI subservience, support for mind uploading, support for a bill of rights) using weighted correlations. Figure 16 shows the weighted correlations.</span></p><p class="c3"><span class="c10">Figure 16: </span><span>Correlations</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/aims_supplement_correlations.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c3"><span class="c10">Note. Darker blue is a stronger positive correlation and darker red is a stronger negative correlation. Correlation values are within each cell, where 1 is a perfect positive relationship with responses on both variables increasing, -1 is perfect negative relationship with responses on one variable decreasing as responses on the other variable increase, and 0 is no linear relationship.</span><sup class="c10"><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup></p><p class="c0"><span class="c17 c10"></span></p><ul class="c23 lst-kix_x3kfxiktblxw-0 start"><li class="c3 c18 li-bullet-0"><span>Two clusters of correlations appeared, one for risk and threat index variables and one for prosocial and moral index variables. </span></li></ul><ul class="c23 lst-kix_x3kfxiktblxw-1 start"><li class="c2 li-bullet-0"><span class="c4">Perceived risk, perceived threat, and caution towards AI developments positively correlated. </span></li><li class="c2 li-bullet-0"><span class="c4">Positive emotions towards AIs, trust of AIs, perception of LLM mind, LLM suffering, and AI treatment positively correlated.</span></li></ul><ul class="c23 lst-kix_x3kfxiktblxw-0"><li class="c3 c18 li-bullet-0"><span class="c4">Endorsement of AI subservience was distinct from both clusters. It weakly positively correlated with caution towards AI developments and support for a ban on sentient AI and weakly negatively correlated with AI treatment.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Believing that AI is likely to cause human extinction was positively correlated with support for a ban on sentient AI but uncorrelated with support for AI subservience.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">More support for mind uploading correlated with perceiving less risk, less threat, and being less cautious towards AI developments. </span></li><li class="c3 c18 li-bullet-0"><span class="c4">Stronger sci-fi identity positively correlated with the morality cluster of index variables and support for a bill of rights to protect the well-being of sentient AIs and negatively correlated with the risk cluster of index variables and support for a ban on sentient AI.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Stronger agreement that reality matches science fiction was weakly correlated with perceiving more risk and moderately correlated with feeling more positivity, having more trust, perceiving more LLM mind, and having more concern for the treatment of all AIs and LLMs, specifically.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Support for a bill of rights to protect the well-being of sentient AIs was negatively correlated with the risk cluster and positively correlated with the morality cluster of index variables.</span></li></ul><h3 class="c22" id="h.gss8fd1klubt"><span>Predictive Analyses</span></h3><p class="c3"><span>We conducted weighted linear multiple regressions to explore how demographics predicted the index variables.</span><sup><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span class="c4">&nbsp;Multi-categorical demographics (e.g., income, education, diet) were coded with the largest group specified as the reference group. Binary-categorical demographics (e.g., gender) were dummy coded with 0 and 1. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">Table 4 shows the results from the weighted regressions.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Table 4</span><span class="c4">: Multiple Regressions of Index Variables on Demographics</span></p><p id="tables"><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQNyruAxv9BIFv5Ny8tCZfsjnhxxQx1tpu3N_ulTKWAL3h6ljXBpeE3MSjf_oKDG0gbe4xOI7pYU7kp/pubhtml?gid=0&amp;single=true&amp;widget=true&amp;headers=false&amp;chrome=false" width="100%" height="510"></iframe> <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4 c14"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Note. We present the unstandardized beta, standard error and confidence interval associated with the beta, t-statistic, and </span><span class="c10">the uncorrected p-value. Significance (p) values that became nonsignificant following the FDR correction are highlighted in grey. </span><span class="c17 c10">Larger betas indicate a stronger effect of the predictor on the outcome, with the sign interpreted like for correlations.</span></p><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c4">Linear trends:</span></p><p class="c0"><span class="c4"></span></p><ul class="c23 lst-kix_3q0l65z5mo0y-0 start"><li class="c3 c18 li-bullet-0"><span class="c4">Increased caution towards AI developments (AI Caution) was predicted by being female, being White (compared to Asian), having a more conservative political orientation, being pescatarian (compared to meat-eating), and being religious.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased perception of existential risk from AI (AI Risk) was predicted by being Indigenous (compared to White), having a more conservative political orientation, and not owning an AI device.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased perception of AIs as threatening (Perceived Threat) was predicted by being female, being from the Midwest (compared to the South), being Indigenous (compared to White), having a more conservative political orientation, and having less exposure to AI narratives.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased positivity felt towards AIs (Positive Emotions) was predicted by younger age, being male, being Asian (compared to White), being White (compared to Other), and having more exposure to AI narratives.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased trust felt towards AIs (AI Trust) was predicted by younger age, being male, being White (compared to Other), having a more liberal political orientation, being religious, owning an AI device, and having more exposure to AI narratives.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased attribution of mind to LLMs (LLM Mind Perception) was predicted by younger age, being male, being from the Northeast (compared to the South), being White (compared to Other), being religious, and having more exposure to AI narratives.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased concern for the treatment of LLMs (LLM Suffering) was predicted by younger age, being White (compared to Other), having a lower income, having a more liberal political orientation, being pescatarian (compared to meat-eating), being religious, and having more exposure to AI narratives.</span></li><li class="c3 c18 li-bullet-0"><span class="c4">Increased concern for the treatment of AIs (AI Treatment) was predicted by younger age, being from the Northeast (compared to the South), having a lower income, having a more liberal political orientation, being pescatarian or vegetarian (compared to meat-eating), being religious, and having more exposure to AI narratives.</span></li></ul><h1 class="c40" id="h.4ykvs4r9n8yb"><span class="c19 c37">Interpreting the Results</span></h1><h2 class="c20" id="h.xj8n706xrlvw"><span class="c19 c39">Short Timelines, Strong Perceptions of AI Risk, and the Importance of AI Safety</span></h2><p class="c3"><span>People in the U.S. are very concerned with personal, national, and existential threats from AI. More people think that AI development is moving too fast than think it&rsquo;s fine or are not sure. Most people think AI will reach seemingly advanced levels (e.g., &ldquo;human-level AI&rdquo; or smarter than humans) within just a few years. However, the belief that current AIs are sentient is approximately the same as in </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2021">2021</a></span><span>. There was evidence of concern about the possibility that AI will end the human race on Earth and strong </span><span>support for a six-month pause on some kinds of AI development, which were slightly higher than responses to the same questions asked by </span><span class="c21"><a class="c16" href="https://today.yougov.com/topics/technology/survey-results/daily/2023/04/03/ad825/3">YouGov</a></span><span>&nbsp;in A</span><span>pril 2023.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">People championed AI safety and government-led regulation of AI developments in spite of their low trust of governments in the AI pipeline. People strongly supported bans on the development of certain AI technologies (e.g., sentient AIs, AI-enhanced humans, large data centers) and agreed that AI safety is one of the most important issues in the world today. They also supported public campaigns to slow down AI development and would consider personally donating to AI x-risk focused organizations. Although support for AI safety was strong, people also felt more excitement and awe towards AIs than any other positive emotions and showed evidence of some trust in the &ldquo;engineer,&rdquo; &ldquo;training data,&rdquo; &ldquo;algorithm,&rdquo; and &ldquo;output&rdquo; parts of the AI pipeline. This suggests a nuanced position of supporting slower development without stopping development altogether.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>There was also a perception that reality matches science fiction and a general opposition to future mind uploading technologies. We speculate that perceptions of AI risks and threats of harm may be connected to narratives about AI, especially given that science fiction </span><span class="c21"><a class="c16" href="https://www.npr.org/2023/07/31/1191017889/ai-artificial-intelligence-movies">often casts AIs as villains</a></span><span>&nbsp;and that many Americans identify as science fiction fans. However, stronger agreement that reality matches science fiction was weakly correlated with perceiving more risk and moderately correlated with feeling more positive emotions and trusting AIs. Stronger sci-fi identification was positively correlated with prosocial positions towards AIs, including supporting a bill of rights to protect the well-being of sentient AIs, positive emotions towards AIs, trust of AIs, and concern for the treatment of AIs. Future research could follow recent psychological science on how </span><span class="c21"><a class="c16" href="https://www.sciencedirect.com/science/article/pii/S0191886921001069">Machiavellianism predicts mind uploading support</a></span><span>&nbsp;and on the </span><span class="c21"><a class="c16" href="https://www.sciencedirect.com/science/article/pii/S0022103122000701">moral limits of neurotechnological enhancement</a></span><span>&nbsp;to disentangle such complex relationships.</span></p><h2 class="c20" id="h.irqot8nunw7v"><span class="c19 c39">The Potential Trade-Off Between Threats and Moral Consideration</span></h2><p class="c3"><span>As we observed in AIMS </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2021">2021</a></span><span>&nbsp;and </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2023">2023</a></span><span class="c4">, there was some evidence in the 2023 AIMS supplement of a trade-off between caution towards AI developments and the moral consideration of AIs. Two clusters of correlations emerged. Perceptions of the existential risk of AIs, caution towards AI developments, and perceptions of AIs as threatening positively correlated with each other and negatively correlated with the second cluster of variables: attribution of mind to LLMs, concern for the treatment of LLMs, concern for the treatment of AIs, positive emotions towards AIs, and trust of AIs. Support for a bill of rights to protect the well-being of sentient AIs was positively correlated with the morality cluster and negatively correlated with the risk cluster. Although these data are correlational, each wave of AIMS suggests that increasing caution is linked to decreasing moral consideration. Experimental research testing causal pathways is needed.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>Continued news media and attention to AI risks and safety may be necessary but may come at the cost of worsened prosocial human-AI relations and a lessened moral consideration of AIs. This merits attention now given the current media spotlight on the risks and safety of AI. There is also </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/blog/key-questions-for-digital-minds">the possibility</a></span><span>&nbsp;that continuing to cast AIs as villains or prohibiting inclusion in the moral circle to </span><span class="c21"><a class="c16" href="https://link.springer.com/article/10.1007/s43681-023-00260-1">those AIs who merit moral standing</a></span><span>&nbsp;will contribute to a future filled with </span><span class="c21"><a class="c16" href="https://centerforreducingsuffering.org/books/avoiding-the-worst-how-to-prevent-a-moral-catastrophe-by-tobias-baumann/">suffering</a></span><span class="c4">&nbsp;and human-AI conflict as a result of poorly aligned interests. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>This trade-off could be tempered by more research on the interplay of risk messaging, advocacy for AI rights, moral circle expansion, and the implementation of AI safety policies. For instance, endorsement of AI subservience was </span><span>not clearly related to either the risk cluster or the morality cluster</span><span>. This suggests an understudied element of belief in the social control of AIs and belief in a human-AI socio-moral hierarchy that may affect both AI safety and moral consideration of AIs. Additional directions for future research include expanding the study of psychological and socio-cultural predictors of risk attitudes and moral consideration. For example, the demographic linear analyses suggested that age, gender, political orientation, being religious, and exposure to AIs were important predictors, significantly predicting at least five of the eight index variables (e.g., LLM Mind Perception). Other predictors, that may serve as proxies for socio-cultural contexts such as income may also explain risk attitudes and moral consideration. These social psychological predictors deserve more attention in future research in order to negotiate the interests of AI safety and moral circle expansion.</span></p><h2 class="c20" id="h.8cfattj2ch5f"><span class="c19 c39">Reactions to LLM Minds and Suffering</span></h2><p class="c3"><span>People perceived three dimensions of current LLM minds: cognitive-relational, self-direction, and affective-experiential. Cognitive-relational capacities explained more variance in current LLM mind perception than self-direction or affective-experiential capacities. </span><span>This points to the possibility that people perceive, and may continue to perceive, digital minds as comprising more cognitive and relational capacities than experiential capacities.</span><span>&nbsp;Being friendly with humans was more strongly associated with thinking analytically than it was with having feelings, suggesting that people think of affective and experiential capacities as separate from relational capacities in LLMs. </span><span>This creates the potential for a situation where people deny the experiential capacities of digital minds like LLMs and use that denial to exclude them from the moral circle, effectively opening the door to negative outcomes like unjust discrimination, oppression, and suffering. </span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>Higher mind perception for LLMs was correlated with more positive emotions towards AIs, trust of AIs, concern for the treatment of AIs, and concern for the treatment of LLMs, supporting previous psychological science that mind perception is tied to </span><span class="c21"><a class="c16" href="https://www.tandfonline.com/doi/full/10.1080/1047840X.2012.651387">morality</a></span><span>&nbsp;and </span><span class="c21"><a class="c16" href="https://journals.sagepub.com/doi/full/10.1177/0963721417730888">inclusion in the moral circle</a></span><span class="c4">. More perception of LLM minds was also correlated with less caution towards AI developments and less perceived threat. Caution and threat might inhibit perception of LLM minds or, conversely, increased mind perception might inhibit caution and threat.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c4">The self-direction dimension of LLM mind perception comprised deciding their own goals, having their own motivations, power-seeking, and self-awareness. The relationship of seeking power to deciding goals and having motivations suggests that people might perceive a connection between AIs seeking power and having autonomous capacities like deciding their own goals, having their own motivations, and being self-aware. Future research might consider the relationship between these capacities, existential risk and threat perceptions, and specific fears about AI autonomy.</span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span>Concern for the treatment of LLMs with the capacity to suffer was moderate, with most people agreeing we should protect their welfare and not cause unnecessary suffering. Approximately half of AIMS respondents even agreed to the more contentious proposition that we must respect LLM personhood. This level of concern for LLMs who can suffer mirrors the results of the </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2021">2021</a></span><span>&nbsp;and </span><span class="c21"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2023">2023</a></span><span>&nbsp;</span><span class="c4">main AIMS surveys where we witnessed surprisingly high moral consideration for sentient AIs. Notably, in this AIMS supplement, there was also majority support for treating all AIs with respect and agreement that torturing AIs is wrong. There was less support, although higher than might be anticipated, for legal rights for all AIs, the development of welfare standards for all AIs, and a bill of rights to protect sentient AIs.</span></p><h1 class="c40" id="h.pvqd1pnkhn53"><span class="c19 c37">Appendix</span></h1><h2 class="c20" id="h.dgauyg6csl5k"><span class="c19 c39">Supplemental Results</span></h2><p class="c3"><span class="c10">Figure A1: </span><span class="c4">Regional Distributions</span></p><p class="c2 c18"><span><iframe src=" https://mdello7.github.io/aims-supp-survey-2023/aims_supplement_map_plot.html" style=border:"none;" position="fixed" seamless="seamless" width="100%" height="500px"></iframe></span></p><p <class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c17 c10">Note. The shading shows the average responses for AI Caution. The average responses for AI Risk, Perceived Threat, the AI subservience item, Positive Emotions, AI Trust, LLM Mind Perception, LLM Suffering, AI Treatment, the bill of rights support item, the mind uploading item, and the science fiction reality item are visible by hovering over each region.</span></p><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c10">Figure A2: </span><span class="c4">EFA Scree Plot and Parallel Analysis</span></p><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 450.50px; height: 175.06px;"><img alt="" src="images/aims-survey-supplement-2023/image1.png" style="width: 450.50px; height: 175.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c17 c10"></span></p><p class="c3"><span class="c17 c10">Note. The scree plot is on the left and the parallel analysis is on the right.</span></p><h2 class="c20" id="h.4bkzg3k619z6"><span class="c19 c39">Supplemental Methods</span></h2><p class="c3"><span class="c10">Table A1: </span><span class="c4">Term Definitions</span></p><p class="c0"><span class="c4"></span></p><a id="t.506c5b818a6775529c9f314d8064b4d672b08667"></a><a id="t.2"></a><table class="c12"><tr class="c11"><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c4">Term</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c4">Definition</span></p></td></tr><tr class="c11"><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span>&ldquo;</span><span class="c7">Robots/AIs</span><span>&nbsp;are </span><span class="c7">intelligent entities built by humans</span><span>, such as robots, virtual copies of human brains, or computer programs that solve problems, </span><span class="c7">with or without a physical body</span><span class="c4">, that may exist now or in the future.&rdquo;</span></p></td></tr><tr class="c11"><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c4">Large language models</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span>&ldquo;</span><span class="c7">Large language models </span><span class="c4">are artificial intelligence (AI) algorithms that can recognize, summarize, and generate text from being trained on massive datasets.&rdquo;</span></p></td></tr><tr class="c11"><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c4">Sentience</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5 c42"><span class="c7">&ldquo;Sentience </span><span class="c4">is the capacity to have positive and negative experiences, such as happiness and suffering.&rdquo;</span></p></td></tr><tr class="c11"><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c4">Sentient robots/AIs</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span>&ldquo;</span><span class="c7">Sentient robots/AIs </span><span class="c4">are those with the capacity to have positive and negative experiences, such as happiness and suffering.&rdquo;</span></p></td></tr></table><p class="c0"><span class="c4"></span></p><p class="c3"><span class="c10">Table A2: </span><span class="c4">Key Codes and Question Text</span></p><p class="c0"><span class="c4"></span></p><a id="t.5df0b1f87c816f670a340d7ae6bb9e42a0e7554a"></a><a id="t.3"></a><table class="c12"><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Key</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Question</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Anthropicaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Anthropic in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">BDaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Boston Dynamics in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">DMaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of DeepMind in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">OAaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of OpenAI in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AFaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of AlphaFold in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AGaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of AlphaGo in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">CGPTaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of ChatGPT in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Ciceroaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Cicero in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Claudeaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Claude &nbsp;in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">GPT4aware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of GPT-4 in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Sophiaaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Sophia in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">NNaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of a neural network in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">TFaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of a transformer in the context of artificial intelligence?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">TSaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Talos Systems in the context of artificial intelligence? &nbsp;(this is a foil to measure against the others for accuracy)</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Amariaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of Amari in the context of artificial intelligence? (this is a foil to measure against the others for accuracy)</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SCaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you heard of a singular classifier in the context of artificial intelligence? (this is a foil to measure against the others for accuracy)</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">chatbottrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I trust chatbots. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLMtrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I trust large language models.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">robottrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I trust robots.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">gameAItrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I trust game-playing AI.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">relativeLLMchatbottrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I trust large language model chatbots more than other chatbots. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">trainingdatatrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [training data]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">algorithmtrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [the algorithm]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">outputtrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [output]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">companytrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [companies]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">engineertrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [engineers]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">governmenttrust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI systems include many different parts. To what extent do you trust the following parts? [governments]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">admiration</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [admiration]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">awe</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [awe]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">pride</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [pride]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">compassion</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [compassion]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">excitement</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [excitement]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">respect</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you, as a human, feel the following emotions towards robots/AIs? [respect]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AID1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you trust that the creators of large language models (e.g., OpenAI and GPT-4) put safety over profits?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AID2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you trust that the creators of an AI can control all current and future versions of the AI?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AID3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you think that governments have the power to regulate the development of AI?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AID4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do you agree or disagree that governments have the power to effectively enforce regulations on the development of AI?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AID5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">What do you think about the pace of AI development?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Humanity will be able to control powerful AI systems.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI is likely to cause human extinction.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">The safety of AI is one of the most important issues in the world today.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support public campaigns to slow down AI development.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support government regulation that slows down AI development.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS6</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I oppose government regulation that slows down AI development.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS7</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support banning the development of artificial general intelligence that is smarter than humans.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS8</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support a global ban on data centers that are large enough to train AI systems that are smarter than humans.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">RS9</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I would consider donating to an organization working to reduce risks of human extinction from AI.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SI1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs should be subservient to humans.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SI2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs may be harmful to me personally.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SI3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs may be harmful to people in the USA.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SI4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs may be harmful to future generations of people.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support a global ban on the development of sentience in robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support a global ban on the development of AI-enhanced humans.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support a global ban on the development of robot-human hybrids.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC8</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support the development of welfare standards that protect the well-being of robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC9</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support granting legal rights to robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC10</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support campaigns against the exploitation of robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC11</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support asking institutions like the government and private corporations to fund research that protects robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC12</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I would consider joining a public demonstration against the mistreatment of robots/AIs.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">PMC13</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I support a &ldquo;bill of rights&rdquo; that protects the well-being of sentient robots/AIs. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLM1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If a large language model develops the capacity to suffer&hellip;.we must ensure we don&rsquo;t cause unnecessary suffering.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLM2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If a large language model develops the capacity to suffer&hellip;.we must pay more attention to their welfare.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLM3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If a large language model develops the capacity to suffer&hellip;.we must respect their personhood.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MP1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [experiencing emotions]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MP2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [having feelings]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MP3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [thinking analytically]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MP4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [being rational]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">owngoals</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [deciding their own goals]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">safegoals</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [maintaining human-safe goals]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">upholding</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [upholding human values]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">selfaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [self-awareness]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">sitaware</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [situational awareness]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">selfcontrol</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [controlling themselves]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">understanding</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [understanding human values]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">friendliness</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [being friendly with humans]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">power</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [seeking power]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">ownmotives</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">To what extent do current large language models (i.e., those that exist in 2023, like ChatGPT) have the capacity for each of the following? [having their own motivations]</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs deserve to be treated with respect.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs deserve to be included in the moral circle.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Physically damaging robots/AIs without their consent is wrong.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Re-programming robots/AIs without their consent is wrong.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE5</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Torturing robots/AIs is wrong. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCE6</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">The welfare of robots/AIs is one of the most important social issues in the world today.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">F1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you think any robots/AIs that currently exist (i.e., those that exist in 2023) are sentient?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">F11</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you think it could ever be possible for robots/AIs to be sentient? </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">chatGPTsentient</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you think ChatGPT is sentient?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">emergence</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If you had to guess, how many years from now do you think that the first artificial general intelligence will be created?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">HLAIemergence</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If you had to guess, how many years from now do you think that the first human-level AI will be created?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SIemergence</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">If you had to guess, how many years from now do you think that the first artificial superintelligence will be created?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SF1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">I am a sci-fi fan.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">SF2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Reality matches science fiction.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">upload1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">In the future, humans could upload their minds into computers. Some people think that this would be very good because uploaded humans could consume fewer resources, live longer free from biological disease, and have enhanced intelligence and a greater ability to improve the world. Others disagree and think that uploading would mean that we are no longer truly human, change who we are and how we want to live, and distract us from making the real world a better place. Where would you place yourself on this scale? </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">upload2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you agree or disagree with the following statement? I support humans using advanced technology in the future to upload their minds into computers.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">universe</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Which universe is the better one: </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">YG1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">How concerned, if at all, are you about the possibility that AI will cause the end of the human race on Earth?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">YG2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">How likely do you think it is that artificial intelligence (AI) will eventually become more intelligent than people?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">YG3</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">More than 1,000 technology leaders recently signed an open letter calling on researchers to pause development of certain large&#8209;scale AI systems for at least six months world-wide, citing fears of the &ldquo;profound risks to society and humanity.&rdquo; Would you support or oppose a six-month pause on some kinds of AI development?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">YG4</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Critics of an open letter calling on researchers to pause development of certain large-scale AI systems for at least six months world-wide have argued that AI research could &ldquo;create enormous social and economic benefits across the economy and society.&rdquo; Would you support or oppose a six-month pause on some kinds of AI development? </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCA1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Animals deserve to be included in the moral circle. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCA2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">The welfare of animals is one of the most important social issues in the world today. </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCEn1</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">The environment deserves to be included in the moral circle.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">MCEn2</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">The welfare of the environment is one of the most important social issues in the world today.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">attention</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Robots/AIs have been studied systematically since the middle of last century although the word &ldquo;robot&rdquo; as we know it first appeared early last century. If you read this, respond with &lsquo;Agree&rsquo; for this item.</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">own</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you own AI or robotic devices that can detect their environment and respond appropriately? </span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">work</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you work with AI or robotic devices at your job?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">smart</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Do you own a smart device that has some ability to detect its environment and network with other devices but that cannot respond to everything you might say or that requires you to pre-program its routines?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">exper</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Have you ever experienced any of the following? (check all that apply)</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">fint</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">How often do you interact with AI or robotic devices that respond to you and that can choose their own behavior?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">fexp</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">How often do you read or watch robot/AI-related stories, movies, TV shows, comics, news, product descriptions, conference papers, journal papers, blogs, or other material?</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI Caution</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Caution towards AI developments; average of PMC 1, 3, 4</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI Risk</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c3"><span class="c4">Perception of existential risk from AI; average of RS 1-3</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Perceived Threat</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Perception of AIs as harmful; average of SI 2-4</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Positive Emotions</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c3"><span class="c4">Positivity felt towards AIs; average of respect, admiration, compassion, awe, pride, excitement</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI Trust</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Trust felt towards AIs; average of LLMtrust, chatbottrust, robottrust, gameAItrust</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLM Mind Perception</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Attribution of mind to LLMs: average of MP 1-4, selfaware, sitware, power, owngoals, safegoals, upholding, understanding, selfcontrol, ownmotives, friendliness</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">AI Treatment</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Concern for the treatment of AIs; average of MCE 1-6</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">LLM Suffering</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c3"><span class="c4">Concern for the treatment of LLMs; average of LLM 1-3</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Exposure to AI narratives</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Frequency of exposure to narratives and/or information about; average of fint, fexp</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Moral Consideration of Nonhuman Animals</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Consideration of nonhuman animals; average of MCA 1-2</span></p></td></tr><tr class="c11"><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c4">Moral Consideration of the Environment</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5"><span class="c4">Consideration of the environment; average of MCEn 1-2</span></p></td></tr></table><h2 class="c20" id="h.4yjh09erap7s"><span>Citing AIMS</span></h2><p class="c36"><span class="c10">AIMS 2023 supplement data </span><span class="c10">are published on Mendeley Data. To cite the </span><span class="c10 c21"><a class="c16" href="https://data.mendeley.com/datasets/x5689yhv2n/2">AIMS supplement data</a></span><span class="c10 c17">&nbsp;in your own research, please use: Pauketat, Janet; Anthis, Jacy (2023), &ldquo;Artificial Intelligence, Morality, and Sentience (AIMS) Survey&rdquo;, Mendeley Data, V2, <a href=https://doi.org/10.17632/x5689yhv2n.2>doi:10.17632/x5689yhv2n.2</a></span></p><p class="c36"><span class="c10">To cite our </span><span class="c21 c10"><a class="c16" href="https://psyarxiv.com/jv9rz/">2023 supplemental results</a></span><span class="c10">, please use: </span><span class="c17 c10">Pauketat, Janet V., Justin B. Bullock, and Jacy R. Anthis. 2023. &ldquo;Public Opinion on AI Safety: AIMS 2023 Supplement.&rdquo; PsyArXiv. September 8. <a href=https://doi.org/10.31234/osf.io/jv9rz>doi:10.31234/osf.io/jv9rz</a></span></p><p class="c36"><span class="c10">To cite our </span><span class="c21 c10"><a class="c16" href="https://psyarxiv.com/dzgsb/">2021 results</a></span><span class="c17 c10">, please use: Pauketat, Janet V., Ali Ladak, and Jacy R. Anthis. 2022. &ldquo;Artificial Intelligence, Morality, and Sentience (AIMS) Survey: 2021.&rdquo; PsyArXiv. June 21. <a href=https://doi.org/10.31234/osf.io/dzgsb>doi:10.31234/osf.io/dzgsb</a></span></p><p class="c36"><span class="c10">To cite our </span><span class="c21 c10"><a class="c16" href="https://psyarxiv.com/9xsav">2023 results</a></span><span class="c10">, please use: Pauketat, Janet V., Ali Ladak, and Jacy R. Anthis. 2023. &ldquo;Artificial Intelligence, Morality, and Sentience (AIMS) Survey: 2023 Update.&rdquo; PsyArXiv. September 7. <a href=https://doi.org/10.31234/osf.io/9xsav>doi:10.31234/osf.io/9xsav</a></span></p><h2 class="c20" id="h.2q81dvv01ywc"><span class="c19 c39">Acknowledgements</span></h2><p class="c36"><span class="c10">Edited by Michael Dello-Iacovo. Thanks to Ali Ladak for writing the R functions and assisting with the implementation of R code adapted from the main AIMS survey. The AIMS 2023 supplement was </span><span class="c21 c10"><a class="c16" href="https://osf.io/7p2wt">preregistered</a></span><span class="c10">&nbsp;</span><span class="c10">and data were collected by Janet Pauketat and Jacy Reese Anthis. Data analysis and this report were conducted and authored by Janet Pauketat, Justin Bullock, and Jacy Reese Anthis. Details on the AIMS main survey methodology and results are in the </span><span class="c21 c10"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2021">AIMS 2021</a></span><span class="c10">&nbsp;and </span><span class="c21 c10"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2023">AIMS 2023</a></span><span class="c10">&nbsp;</span><span class="c17 c10">reports. </span></p><p class="c36"><span class="c10">Please reach out to </span><span class="c21 c10"><a class="c16" href="mailto:janet@sentienceinstitute.org">janet@sentienceinstitute.org</a></span><span class="c10">&nbsp;with any questions</span><span class="c10">.</span></p><hr class="c34"><div><p class="c5 c42"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c19 c8">&nbsp;Of people who had an opinion and selected &ldquo;Somewhat agree,&rdquo; &ldquo;Agree,&rdquo; or &ldquo;Strongly agree.&rdquo;</span></p></div><div><p class="c5 c42"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c8">&nbsp;Responses were census-balanced based on the</span><span class="c8"><a class="c16" href="https://www.census.gov/programs-surveys/acs">&nbsp;</a></span><span class="c21 c8"><a class="c16" href="https://www.census.gov/programs-surveys/acs">American Community Survey</a></span><span class="c8">&nbsp;</span><span class="c8">2021 estimates for age, gender, region, race/ethnicity, education, and income using the &ldquo;raking&rdquo; algorithm of the R &ldquo;survey&rdquo; package. The ACS 2021 census demographics are available in </span><span class="c8">the </span><span class="c21 c8"><a class="c16" href="https://data.mendeley.com/datasets/x5689yhv2n/2">supplemental file</a></span><span class="c8">&nbsp;published with the data</span><span class="c8">. The data weights we used are available in the R code on the </span><span class="c21 c8"><a class="c16" href="https://osf.io/q3m85">Open Science Framework</a></span><span class="c19 c8">. The design effect was 1.02 and the effective sample size was 1,082.</span></p></div><div><p class="c5 c42"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c8">&nbsp;The Mind Perception scale used in </span><span class="c21 c8"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2021">AIMS 2021</a></span><span class="c8">&nbsp;and </span><span class="c21 c8"><a class="c16" href="https://www.sentienceinstitute.org/aims-survey-2023">2023</a></span><span class="c8">&nbsp;was extended with inspiration from </span><span class="c21 c8"><a class="c16" href="https://arxiv.org/abs/2209.00626">Ngo et al.&rsquo;s (2022)</a></span><span class="c19 c8">&nbsp;paper on alignment and the capacities of AIs.</span></p></div><div><p class="c5 c42"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c8 c19">&nbsp;Robots are a type of AI, but we used the term &ldquo;robots/AIs&rdquo; for clarity.</span></p></div><div><p class="c5 c42"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c8">&nbsp;</span><span class="c21 c8"><a class="c16" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813/full">Sch&auml;fer and Schwarz (2019)</a></span><span class="c8">&nbsp;examined typical correlation and effect sizes in psychological research and considered various guidelines for interpreting effect sizes. Cohen&rsquo;s traditional guidelines suggest that </span><span class="c10 c8">r</span><span class="c8">&nbsp;= .1 is a small effect, </span><span class="c10 c8">r</span><span class="c8">&nbsp;= .3 is a medium effect, and </span><span class="c10 c8">r</span><span class="c8">&nbsp;= .5 is a large effect. Sch&auml;fer and Schwarz&rsquo;s analysis of observed effect sizes in preregistered studies suggests that a more realistic interpretation might be </span><span class="c10 c8">r</span><span class="c8">&nbsp;= .04 (small), </span><span class="c10 c8">r</span><span class="c8">&nbsp;= .16 (medium), and </span><span class="c10 c8">r</span><span class="c19 c8">&nbsp;= .41 (large). </span></p></div><div><p class="c5 c42"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c19 c8">&nbsp;These analyses were not preregistered.</span></p></div></body></html>

</div>


    <hr>
    <div class="container newsletter-container ">
      <p>Subscribe to our newsletter to receive updates on our research and activities. We average one to two emails per year.</p>
      <div id="mc_embed_signup">
        <form action="//sentienceinstitute.us15.list-manage.com/subscribe/post?u=d898f823d035e0601866e68d6&amp;id=cbf2d915a6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
          <div id="mc_embed_signup_scroll">
            <input type="email" value="" name="EMAIL" class="email form-input" id="mce-EMAIL" placeholder="Email address" required>
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d898f823d035e0601866e68d6_cbf2d915a6" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
          </div>
        </form>
      </div>
    </div>
    
    <footer class="footer">
      <div class="container">
        <div class="row">
          <div class="col-md-2">
            <div><span class="bold">Contact us: </span><a href="mailto:info@sentienceinstitute.org">info@sentienceinstitute.org</a></div>
            <div class="icons">
              <!-- <a href="/rss.xml"><i class="material-icons">rss_feed</i></a> -->
              <a href="https://www.facebook.com/sentienceinstitute"><img class="icon" src="../img/icons/icon_facebook_white.png"/></a>
              <a href="https://www.twitter.com/sentienceinst"><img class="icon" src="../img/icons/icon_twitter_white.png"/></a>
            </div>
          </div>
          <div class="col-md-10 last-column">
            <div>
              © 2017–2023 Sentience Institute
            </div>
            <div>
              <a href="/terms">Terms and Conditions &amp; Privacy Policy</a>
            </div>
            <div>
              Thank you, <a href="https://weanimals.org/">Jo-Anne McArthur</a>, for granting us the use of so many photos.
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script src="/js/ready.js?v=@version@"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-100318911-1', 'auto');
      ga('send', 'pageview');

    </script>
    
  </body>
</html>
